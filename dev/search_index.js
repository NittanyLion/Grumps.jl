var documenterSearchIndex = {"docs":
[{"location":"installation/#Installation-and-invocation","page":"Installation","title":"Installation and invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"First, ensure that you have Julia version 1.8 or later installed.  Julia can be downloaded from Julia downloads page.  Grumps will not work with older versions of Julia.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"There are two sets of explanation below.  The first bit covers how to install Grumps before it is included in the Julia package system.  This is more cumbersome and will not be needed in the future.","category":"page"},{"location":"installation/#For-now","page":"Installation","title":"For now","text":"","category":"section"},{"location":"installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"First pull the main branch of Grumps from Github.  Then install all required packages by running the code in temp/installrequiredpackages.jl.  That is all that is needed for installation.","category":"page"},{"location":"installation/#Invocation","page":"Installation","title":"Invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Fire up Julia using julia -t 4 replacing the number 4 with whatever number of threads you wish to use (or auto to automatically use all threads in your computer).  The recommended number is the number of physical cores in your computer, which is usually less than the total number of threads (often by a factor of two).  As a permanent solution, one can set the JULIA_NUM_THREADS environment variable.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Then type:","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"    push!( LOAD_PATH, \"*wherever Grumps.jl/src is located*\" )\n    using Grumps","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Now you're good to go.  You can alternatively invoke Julia from the command line with the name of the file containing your code, which should have the above two lines at the top.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"In lieu of specifying LOAD_PATH on every call, one can set the JULIA_LOAD_PATH environment variable in one's operating system.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Please do not try to install or invoke Grumps any other way until it is in the Julia package ecosystem.","category":"page"},{"location":"installation/#Once-Grumps-is-in-the-Julia-package-ecosystem","page":"Installation","title":"Once Grumps is in the Julia package ecosystem","text":"","category":"section"},{"location":"installation/#Installation-2","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Package installation is achieved in the usual way, i.e. by typing ]add Grumps in REPL.  ","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"The REPL is the environment that opens up if you start Julia without arguments or which you automatically get with virtual studio code, the preferred editor for Julia.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"So once you have started Julia, type the character ]: this will open the packaging system for you.  Then type add Grumps; this will install Grumps.  Finally, hit the backspace key to take yourself out of the packaging system again.","category":"page"},{"location":"installation/#Invocation-2","page":"Installation","title":"Invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Fire up Julia using julia -t 4 replacing the number 4 with whatever number of threads you wish to use (or auto to automatically use all threads in your computer).  The recommended number is the number of physical cores in your computer, which is usually less than the total number of threads (often by a factor of two).  As a permanent solution, one can set the JULIA_NUM_THREADS environment variable.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Grumps can then be loaded with using Grumps.  That's it: you're ready to go.","category":"page"},{"location":"estimators/#Estimators","page":"Estimators","title":"Estimators","text":"","category":"section"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The text below describes the estimators that Grumps can compute.  To select one, refer to the Estimator choice section.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The estimator proposed by Grieco, Murry, Pinkse, and Sagl minimizes the sum hatOmega of three objective functions, (minus) a micro loglikelihood, (minus) a macro loglikelihood, and a GMM type quadratic objective function: see Grieco, Murry, Pinkse, and Sagl (2022) for details.  ","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"There are three parameter vectors to be estimated: betathetadelta.  Since beta can be easily estimated off delta and the data, the remainder of this discussion focuses on the estimation of thetadelta.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The full Grumps (CLER) estimator minimizes hatOmega over delta for a given theta in an inner loop and then minimizes over theta in an outer loop.  This is efficient, but costly.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"An estimator that is asymptotically equivalent but less expensive computationally, only minimizes with respect to delta over minus the sum of the loglikelihoods in an inside loop and minimizes hat Omega over theta in the outside loop: we refer to this as the cheap option.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"Then there is the unpenalized maximum likelihood estimator, which drops the GMM term in both the inside and outside loops.  This estimator is not conformant (see the paper for its definition) and is therefore inferior to each of the above two estimators.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"A fourth estimator maximizes the macro loglikelihood in the inside loop and the sum of the two loglikelihoods in the outside loop.  This share constraint estimator is inferior to the unpenalized maximum likelihood estimator.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"One can also use Grumps to compute a mixed logit, which would drop the macro loglikelihood entirely.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"Finally, there is an unfinished implementation of a moments estimator, which should not be used.","category":"page"},{"location":"flow/#Algorithm-flow","page":"Algorithm flow","title":"Algorithm flow","text":"","category":"section"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"(Image: algorithm flow)","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"When Grumps is called using the grumps! call, it runs the grumps! method in est.jl in the optim folder.  This sets up various objects and then calls an optimizer with an objective function that is estimator-specific.  In other words, it will call a different method depending on the e argument in ObjectiveFunctionθ! in est.jl in the optim folder.","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"These methods ObjectiveFunctionθ! are defined either in one of the Julia files in the optim folder whose name starts with obj, or in a specific estimator folder; see estimators folder.  ObjectiveFunctionθ! then decides which internal optimizer (i.e. one that finds delta) to call: they're all called grumpsδ!.","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"After optimization is completed, Grumps will call a standard error computation routine and then return.","category":"page"},{"location":"misc/#Miscellanea","page":"Miscellanea","title":"Miscellanea","text":"","category":"section"},{"location":"misc/#Reducing-data-load-times","page":"Miscellanea","title":"Reducing data load times","text":"","category":"section"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"Grumps uses three packages that have significant overhead when they are first called.  This is most noticeable when loading small datasets and mostly an issue if you run Julia in batch mode from the command line, as opposed to from within the REPL (except on the first run from within the REPL).  To avoid this overhead, one can use the PackageCompiler package.  To use it, do the following:","category":"page"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"add the PackageCompiler using ]add PackageCompiler in the REPL.\ncopy the contents of the extras folder on the github Grumps repository to your computer\nrun julia makesystemimage.jl\nthen, in the future, run julia -J *location of image.so* *other options*","category":"page"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"warning: New Julia versions\nThis procedure would have to be repeated every time you upgrade Julia to a new version\"","category":"page"},{"location":"misc/#Random-tips","page":"Miscellanea","title":"Random tips","text":"","category":"section"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"In most programming languages, it is a bad idea to use global variables.  This is especially true in Julia.  So bury any variable definitions, etcetera, inside a function.  You may incur a significant performance hit if you don't.\nIf one used an estimated sigma_xi^2 in a two stage procedure, then the estimated sigma_xi^2 can be made arbitrarily small by adding many regressors to the delta on x regression.  This is a bad idea since it artificially puts all the weight on the product level moments.","category":"page"},{"location":"speedmemory/#Speed,-memory,-and-accuracy","page":"Speed, memory, accuracy","title":"Speed, memory, and accuracy","text":"","category":"section"},{"location":"speedmemory/#Memory-conservation","page":"Speed, memory, accuracy","title":"Memory conservation","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"By default, Grumps loads all data and then creates space for all markets for things like choice probabilities, objective functions and their derivatives, intermediate objects, etcetera.  This saves computation time, but eats memory, especially as the number of random coefficients increases.","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"There are several ways of addressing memory issues.  First, it is generally a good idea to be modest in the number of random coefficients one uses.  Absent second choice data, it would be rare to be able to estimate more than two, maybe three, random coefficients accurately, even with the CLER estimator implemented in Grumps.  In terms of computation it adds to memory demands.","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"Second, one can set memsave in OptimizationOptions() to true.  What this does is that it shares space for choice probabilities and related objects across a number of markets.  For instance, if there are ten markets and the number of market threads in OptimizationOptions() is set to two then the space for choice probabilities is shared across five markets.  These choices will have no effect if the number of market threads is no less than the number of markets.  The downside of doing this is that it slows down computation since choice probabilities need to be recomputed.  This is especially true for estimators that use the penalty term in the inside optimization, i.e. currently only the full Grumps estimator.  A secondary downside is that to implement this feature without excessive allocations, the code to achieve this is low-level.  In particular, do not call grumps! from different threads in the same program (different processes is fine) when using memsave.","category":"page"},{"location":"speedmemory/#Speed","page":"Speed, memory, accuracy","title":"Speed","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"tip: There are several reasons that would make Grumps slow.\nGrumps can naturally take a while if the data set is large.  \nComputation time grows fast in the number of random coefficients.  \nThe full CLER estimator (especially with memsave on) is slower than its cheap alternative.  \nUsing global variables is a bad idea in any programming language and especially in Julia (bury everything inside a function). In Julia type stability can also be an issue.\nTolerances and iteration counts (not an issue with the defaults).\nUsing robust choice probabilities makes run times longer (the default is fast). \nMake sure you are not running Julia in single thread mode.  Start Julia with julia -t 16 if you have 16 physical cores in your computer.\nThe number of threads used for various activities can be specified via OptimizationOptions().  The defaults may not be optimal, but are usually ok.\nUsing a BigFloat type instead of Float64 adds precision but the performance penalty is severe.","category":"page"},{"location":"speedmemory/#Accuracy","page":"Speed, memory, accuracy","title":"Accuracy","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"The main things one can do to improve accuracy is to experiment with the tolerances.  Other options that would slow down computation are to use robust choice probabilities and higher precision floating points types, but that should be an option of last resort.","category":"page"},{"location":"aliens/#Interacting-with-other-languages","page":"Languages other than Julia","title":"Interacting with other languages","text":"","category":"section"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"There is only a version of Grumps for Julia.  However, you can call other languages from Julia using one of the PyCall, PythonCall, or RCall packages.  You can load Stata files via the StatFiles package.  To call C or Fortran code, see the Julia documentation.  For those using other software like Gauss and Matlab, consider writing results to disk and then reading them in the software you use.","category":"page"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"The code below provides an example in which the output is printed in Julia, Python, and R, respectively.","category":"page"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"using Grumps, PyCall, RCall\n\n\nfunction compute_stuff( meth  )\n\n    s = Sources(                                                            \n      consumers = \"example_consumers.csv\",\n      products = \"example_products.csv\",\n      marketsizes = \"example_marketsizes.csv\",\n      draws = \"example_draws.csv\"  \n    )\n    \n    v = Variables( \n        \"choice = income * constant + income * ibu + age * ibu + rc * ibu + rc * abv\",\n        \"share = constant + ibu + abv / constant, ibu, abv, IVgh_ibu, IVgh_abv\";\n        outsidegood = \"product 11\"                                \n    )\n    \n    e = Estimator( meth )                                                     \n    d = Data( e, s, v ) \n    return grumps!( e, d )           \nend\n\npy\"\"\"\ndef print_my_stuff_in_python(x):\n\tprint( \"Python: \", x )\n\n\"\"\"\n\nR\"\"\"\nprint_my_stuff_in_R <- function(x) cat( \"R: \", x, \"\\n\" ) \n\"\"\"\n\nfunction myprogram( )\n    sol = compute_stuff( :cheap )\n    θcoef =  getθcoef( sol )\n    println( \"Julia: $θcoef \\n\" )\n    py\"print_my_stuff_in_python\"(θcoef)\n    R\"print_my_stuff_in_R\"(θcoef)\nend\n\n\nmyprogram()","category":"page"},{"location":"bearinmind/#Things-to-bear-in-mind","page":"Things to bear in mind","title":"Things to bear in mind","text":"","category":"section"},{"location":"bearinmind/#Starting-values","page":"Things to bear in mind","title":"Starting values","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The global objective function is nearly convex in delta, so convergence of the inner optimization is generally uneventful.  Although the objective function is not convex in theta, the outer optimization often achieves the (near) optimum from a single starting value.  However, this is not guaranteed.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The most frequent case in which this would go wrong is when one or more of the theta^nu coefficients goes to zero and gets stuck.  This is more likely to happen when there are identification problems, e.g. when theta^z approx 0 and the product level moments do not provide much identifying power.  Just try a few other starting values.","category":"page"},{"location":"bearinmind/#Number-of-random-coefficients","page":"Things to bear in mind","title":"Number of random coefficients","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The program will become memory-hungry when the number of random coefficients is increased (assuming micro data are used).  There is a secondary problem that estimating many random coefficients will make estimating those random coefficients accurately more questionable.  Look at the memsave option to reduce memory consumption.","category":"page"},{"location":"bearinmind/#Zero-shares","page":"Things to bear in mind","title":"Zero shares","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) offers some robustness to shares that are equal to or very close to zero.  However, that requires that the product level moments are overidentified.","category":"page"},{"location":"bearinmind/#Efficiency","page":"Things to bear in mind","title":"Efficiency","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) requires an optimal weight matrix for the product level moments (GMM) portion if there is overidentification in the product level moments.  Currently, the algorithm assumes homoskedasticity and independence and produces correct estimates and standard errors under that assumption.  However, to obtain efficiency under those conditions one would have to estimate the error variance sigma_xi^2 and rerun the algorithm using the estimated sigma_xi^2 as a weight: see DataOptions on how to enter that choice.  Absent homoskedasticity and independence, one can transform the instruments to achieve the same goal.  This is something the use will have to do for herself in the current version of Grumps.  Note that the second stage can be started at the first stage estimates and should not take long to converge (relative to the first stage).","category":"page"},{"location":"bearinmind/#Floating-point-numbers","page":"Things to bear in mind","title":"Floating point numbers","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"All numbers should be in the same floating point format.  The default (and only heavily tested) format is Float64, i.e. a 64-bit float.  But the code is designed to handle other formats.  This could be attractive if greater precision is desired.  So one could use some form of BigFloat, at the expense of increased memory use and a substantial increase in computation time.","category":"page"},{"location":"bearinmind/#Nesting-of-memsave","page":"Things to bear in mind","title":"Nesting of memsave","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"If the memsave option (see Optimization options and Memory conservation) is set to true then Grumps will use some low level code to avoid having to repeatedly allocate and free memory.  What this means is that it is a bad idea to have grumps! called from multiple threads simultaneously: from multiple processes should be fine.  If you do not know what this means then you should be ok. ","category":"page"},{"location":"objects/#User-Interface","page":"User interface","title":"User Interface","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The sections below describe the main calls needed to use Grumps.  For any functions that are not documented here, simply use ? in the REPL, e.g. ?Variables.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The way that Grumps works is that one first specifies where the data are stored, what specification to use, which estimator to use, etcetera, before calling the functions that actually perform work with these choices.  All sections below up to and including the choice of integration method specify things, data object creation and algorithm call create and compute things, and the remainder deals with the retrieval of estimation results and memory conservation.","category":"page"},{"location":"objects/#Data-entry","page":"User interface","title":"Data entry","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The methods below are used to enter data into Grumps.  With Sources() one specifies where the data can be found and with Variables() which variables to use from those data sources.  ","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Two versions of the Variables method\nThere are two versions of the Variables method, where the main difference is the syntax.  Use whichever one you prefer.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Sources()\nVariables()\nVariables( ::String, ::String, ::String, ::String )","category":"page"},{"location":"objects/#Grumps.Sources-Tuple{}","page":"User interface","title":"Grumps.Sources","text":"Sources( \n    T           = DefaultSourceTypes; \n    consumers   :: Any = nothing, \n    products    :: Any = nothing, \n    marketsizes :: Any = nothing, \n    draws       :: Any = nothing,\n    user        :: Any = nothing\n)\n\nCreates a GrumpsSources object with source type entries of type T where the entries are provided in the optional parameters.\n\nGrumps (potentially) uses four data sources: a data source for consumer-level data, one for product-level data, one for market size information, and one for demographic draws.  Only the product-level data are required, but are by themselves insufficient.  For instance, for BLP95 one needs information on products, market sizes, and demographics; for the Grumps estimator one needs all four types of data; for a multinomial logit both consumer and product information are needed.  Not all data are needed for all markets.  For instance, it is ok for some estimators for there to be consumer-level data in some markets but not others.\n\nThe T argument is mostly there to allow for future expansion, so the description below applies to the case in which T = DefaultSourceTypes.\n\nBy default, the entries can be nothing, a string, a DataFrame, or a SourceFileType.  If an entry is nothing, it means that no such data is to be used.  If an entry is a string then it is converted to a SourceFileCSV entry with comma delimiter where the string name is the file name.  To use other source file types, create a SourceFileType first.  A DataFrame can be passed, also.  In all cases other than nothing, data will eventually be (converted to) a DataFrame and parsed from that.\n\nThe consumers variable specifies where consumer-level data can be found, the products variable is for the product-level data, marketsizes is for market sizes, and draws is for demographic draws; user has not been implemented yet.\n\nUse the Variables() method to specify the way the data sources are formatted and the specification to estimate.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Variables-Tuple{}","page":"User interface","title":"Grumps.Variables","text":"Variables( ; \n  market              :: Symbol = :market,\n  choice              :: Symbol = :choice,\n  interactions        :: Mat{Symbol} = [],\n  randomcoefficients  :: Vec{Symbol} = [],\n  outsidegood         :: String = \"outsidegood\",\n  share               :: Symbol = :share,\n  marketsize          :: Symbol = :N,\n  regressors          :: Vec{Symbol} = [],\n  instruments         :: Vec{Symbol} = [],\n  dummies             :: Vec{Symbol} = [],\n  nuisancedummy       :: Symbol = :none,\n  microinstruments    :: Mat{Symbol} = [],\n  user                :: Mat{Symbol} = []\n    )\n\nThis method is used to specify regressors, instruments, random coefficients, interactions, variable labels, etcetera, from the sources you have specified in Sources(). It creates an object of type GrumpsVariables.\n\nFor instance, the option market specifies the column heading of the column containing the market descriptor (name).  The same is true for all other arguments, except outsidegood which describes the spreadsheet entry that indicates the product is an outside good.  The  same label for the outside good should be used in all spreadsheets and all markets. Outside good entries  should only be used in the consumer micro data and then only if there actually are consumers in the micro data choosing the outside good. All descriptors are case and space sensitive.\n\nThere is a separation between variables that go into the individual consumer utility and ones that only go into \"mean utility\".  For instance, interactions tells Grumps which interaction terms to use and randomcoefficients which product level regressors are hit with a random coefficient.  By contrast, regressors go into the mean utility component and are regressors in the \"second stage\" (where β is recovered). One can use the special symbol :constant to indicate a constant is to be used; the spreadsheet need not include a column with that heading.\n\nNote that there are three ways that dummy variables can be entered as second stage regressors.  The first is via regressors, in which case the onus is on the user to ensure that they have the correct numerical values.  The second possibility is via the dummies argument.  For  each symbol passed via the dummies argument, Grumps will examine the corresponding column of the product data set (which can contain descriptive entries that need not be numerical) and turn it into dummy variables.  If the coefficient on the dummies is of no interest then it is better to pass one via the nuisancedummy argument since it saves both computation time and memory.  There can only be at most one categorical variable that can be converted to nuisance dummies, but there can be arbitrarily many categories.  These dummies and nuisance dummies are automatically assumed to be exogenous and will be included in the instruments, also.\n\nmarket refers to the variable containing the market indicator in all input datasets.  Strings work best for the market indicators themselves, but it is not a requirement.\n\nproduct refers to the variable containing the product indicator in the product dataset. Strings work best for the product indicators themselves, but it is not a requirement.\n\nchoice refers to the variable indicating the choice indicator in the consumer level datasets.  Strings work best for the choice indicators themselves, but it is not a requirement.\n\ninteractions refers to the variables indicating consumer and product variable interactions (each row contains consumer variable, product variable)\n\nrandomcoefficients refers to the product level variables that have a random coefficient on them\n\noutsidegood refers to the label used for the outside good\n\nshare refers to the label used for the product level share; these are shares where the denominator includes the outside good\n\nmarketsize refers to the size of the market (number of people)\n\nregressors refers to the label used for the second stage regressors\n\ninstruments refers to the label used for the second stage instruments\n\ndummies refers to discrete variables to be converted to second stage dummy regressors and instruments\n\nnuisancedummy refers to at most one variable to be converted to a second stage dummy regressors and instrument whose coefficient value is of no interest\n\nmicroinstruments refers to micro instruments, which are only relevant for gmm style procedures\n\nuser refers to a list of variables to be added to the consumer-product interactions using a user-specified procedure\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Variables-NTuple{4, String}","page":"User interface","title":"Grumps.Variables","text":"Variables( \n    microspec           :: String,\n    macrospec           :: String,\n    dummyspec           :: String = \"\",\n    nuisancedummyspec   :: String = \"\";\n    market              :: String = \"market\",\n    product             :: String = \"product\",\n    outsidegood         :: String = \"outsidegood\",\n    marketsize          :: String = \"N\",\n    microinstruments    :: String = \"\",\n    user                :: String = \"\"\n    )\n\nThis method is used to specify regressors, instruments, random coefficients, interactions, variable labels, etcetera, from the sources you have specified in Sources(). It creates an object of type GrumpsVariables.  There is another method by the same name that accomplishes much the same thing, but has a different user interface. \n\nThe method described here takes string arguments, including two mandatory ones, whereas the other method takes optional arguments only, mostly symbols, vectors of symbols, and matrices of symbols that can be passed in arbitrary order using keywords.  The current method parses user input before calling the other method.\n\nThe option market specifies the column heading of the column containing the market descriptor (name).  The same is true for all other  arguments, except outsidegood which describes the spreadsheet entry that indicates the product is an outside good.  The same label for  the outside good should be used in all spreadsheets and all markets. Outside good entries should only be used in the consumer micro data  and then only if there actually are consumers in the micro data choosing the outside good. All descriptors are case sensitive.\n\nThere is a separation between variables that go into the individual consumer utility and ones that only go into \"mean utility\".  For instance, to specify what goes into individual consumer utility, one could specify\n\n\"choice = loginc * msrp + famsize * logfootprint + famsize * van + urban * truck + rc * suv + rc * truck + rc * van\"\n\nas the microspec argument to indicate that consumer choice is in the micro data set in a column headed \"choice\" and that there are four interaction terms and three random coefficients.  The interaction terms have the consumer-level variable as the first factor and the product  variable as the second argument.  In this example the three random coefficients are on the suv, truck, and van variables and these variable names should correspond to the column headings in the product level data set.  One can use constant to indicate a constant is used: there is no need to include a constant in one's data.\n\nThe macrospec argument takes the form \n\n\"share = constant + logmpg + loghp + logfootprint + msrp / constant, logmpg, loghp, logfootprint, logcurbweight, lagplcon\"\n\nwhere share are product-level market shares, everything between = and / represents regressors, and everything after / represents  instruments; both regressors and instruments are for the product level moments portion.  One can again use constant to indicate a constant is used, which need not be included in one's data.\n\nNote that there are three ways that dummy variables can be entered as second stage regressors.  The first is via macrospec, in which case the onus is on the user to ensure that they have the correct numerical values.  The second possibility is via the dummyspec argument.  For  each variable passed via the dummyspec argument, Grumps will examine the corresponding column of the product data set (which can contain descriptive entries that need not be numerical) and turn it into dummy variables.  If the coefficient on the dummies is of no interest then it is better to pass one via the nuisancedummyspec argument since it saves both computation time and memory.  There can only be at most one categorical variable that can be converted to nuisance dummies, but there can be arbitrarily many categories.  These dummies and nuisance dummies are automatically assumed to be exogenous and will be included in the instruments, also.\n\nmarket refers to the variable containing the market indicator in all input datasets.  Strings work best for the market indicators themselves, but it is not a requirement.\n\nproduct refers to the variable containing the product indicator in the product dataset. Strings work best for the product indicators themselves, but it is not a requirement.\n\nchoice refers to the variable indicating the choice indicator in the consumer level datasets.  Strings work best for the choice indicators themselves, but it is not a requirement.\n\ninteractions refers to the variables indicating consumer and product variable interactions (each row contains consumer variable, product variable)\n\nrandomcoefficients refers to the product level variables that have a random coefficient on them\n\noutsidegood refers to the label used for the outside good\n\nshare refers to the label used for the product level share; these are shares where the denominator includes the outside good\n\nmarketsize refers to the size of the market (number of people)\n\nregressors refers to the label used for the second stage regressors\n\ninstruments refers to the label used for the second stage instruments\n\ndummies refers to discrete variables to be converted to second stage dummy regressors and instruments\n\nnuisancedummy refers to at most one variable to be converted to a second stage dummy regressors and instrument whose coefficient value is of no interest\n\nmicroinstruments refers to micro instruments, which are only relevant for gmm style procedures\n\nuser refers to a list of variables to be added to the consumer-product interactions using a user-specified procedure\n\n\n\n\n\n","category":"method"},{"location":"objects/#Optimization-options","page":"User interface","title":"Optimization options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default optimization options are sensible, in which case this section can be skipped.  But for those who want to play with tolerances and such, have at it.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"There is one exception, however, and that exception pertains to using less memory.  There is a separate section dedicated to that possibility, namely Memory conservation","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"OptimizationOptions()\nOptimOptionsθ()\nOptimOptionsδ()\nGrumpsThreads(; blas = 0, markets = 0, inner = 0 )","category":"page"},{"location":"objects/#Grumps.OptimizationOptions-Tuple{}","page":"User interface","title":"Grumps.OptimizationOptions","text":"OptimizationOptions(; \nθopt = OptimOptionsθ(), \nδopt = OptimOptionsδ(), \nthreads = GrumpsThreads(), \nmemsave = false, \nmaxrepeats = 4, \nprobtype = :fast,\nid = :Grumps\n)\n\nSets the options used for numerical optimization.  θopt is used for the external optimization routine, δopt for the internal one.  These are both of type OptimOptions; see the OptimOptionsθ and OptimOptionsδ methods for elaboration.  The memsave variable is set to false by default; turning it on will reduce memory consumption significantly, but will also slow down computation.  The variable maxrepeats may disappear in the  future.  \n\nThere are two ways of computing choice probabilities: robust and fast, specified by passing :robust or :fast in probtype. Fast choice probabilities are the default for good reason.\n\nFinally, specifying a callback allows one to add callbacks, i.e. user functions that are called on each inner and  outer iteration.  See the Extending Grumps portion of the documentation.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsθ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsθ","text":"OptimOptionsθ(; \nf_tol = 1.0e-8, \ng_tol = 1.0e-4, \nx_tol = 1.0e-5, \niterations = 25, \nshow_trace = true, \nstore_trace = true, \nextended_trace = true )\n\nCreates and returns an OptimOptions optimization options variable for the outer optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsδ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsδ","text":"OptimOptionsδ( ; \nf_tol = 1.0e-8, \ng_tol = 1.0e-8, \nx_tol = 1.0e-6, \niterations = 25, \nshow_trace = false, \nstore_trace = true, \nextended_trace = false )\n\nCreates and returns an OptimOptions optimization options variable for the inner optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.GrumpsThreads-Tuple{}","page":"User interface","title":"Grumps.GrumpsThreads","text":"GrumpsThreads(; \n    blas = 0, \n    markets = 0, \n    inner = 0 \n    )\n\nThis sets the number of threads to be used subject to a number of caveats.  blas refers to the number of BLAS threads, markets to the number of threads in loops over markets, and inner to the number of threads in inner loops.  A value of zero forces the automatic selection of the number of threads.\n\nOf these, inner is not currently used at all, market is only used in memsave mode, and blas is used.  However, please note that the number of threads used by Grumps altogether is the number of threads passed in via the command line argument (i.e. via the -t switch), where that number does not include the number of BLAS threads set.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Data-storage-options","page":"User interface","title":"Data storage options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default data storage options are sensible, but some space can be saved by tinkering with the settings.  However, the only parameter that is worth changing is σ2, which is the variance of ξ, the product level error term.  This is of no relevance for two-stage estimators like unpenalized mle.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"DataOptions()","category":"page"},{"location":"objects/#Grumps.DataOptions-Tuple{}","page":"User interface","title":"Grumps.DataOptions","text":"DataOptions(; \n    micromode   = :Hog\n    macromode   = :Ant\n    balance     = :micro\n    σ2          = 1.0\n    id          = :Grumps\n)\n\nSpecifies how Grumps should store its data and what it should store.  The first three options are best left alone, unless you know what it is you're doing.  The σ2 option is the variance of ξ, i.e. the error variance in the product level moments.  The id option is used to extend Grumps with other data constructions.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Standard-error-options","page":"User interface","title":"Standard error options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"stub","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"StandardErrorOptions()","category":"page"},{"location":"objects/#Grumps.StandardErrorOptions-Tuple{}","page":"User interface","title":"Grumps.StandardErrorOptions","text":"StandardErrorOptions(; θ = true, δ = true, β = true, setype = :homo )\n\nSpecifies which coefficients to create standard errors for and what type of standard errors to produce.  Current choices are :homo (i.e. assuming homoskedasticity) and :hetero (heteroskedasticity-robust).  Fancier options will be added at a future point in time.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Estimator-choice","page":"User interface","title":"Estimator choice","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps can compute quite a few estimators and one can specify which estimator to use by passing the return value of a call to Estimator to the optimization routine.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The easiest way to call Estimator is by passing it a string that describes what it is that you want to do.  The following estimators are currently defined:","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"the full Grumps (CLER) estimator\na less expensive alternative estimator with the same limit distribution as the CLER estimator\nGrumps-style maximum likelihood, i.e. CLER without penalty\nditto, but imposing share constraints\nGMM estimator that uses both micro and macro moments and uses quadrature instead of Monte Carlo draws in the micro moments.  The micro moments are smart in that they condition on z_im instead of integrating it out.\na mixed logit estimator","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"For a description of these estimators, see Estimators.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Estimator( s :: String )\nEstimator( s :: Symbol )\nEstimators()","category":"page"},{"location":"objects/#Grumps.Estimator-Tuple{String}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: String )\n\nCreates and returns a GrumpsEstimator type.  Grumps is reasonably good at figuring out what it is that you want, so e.g. Estimator( \"maximum likelihood\" ) gives you the unpenalized Grumps maximum likelihood estimator.\n\nThe estimators currently programmed include:\n\nthe full Grumps estimator\na cheaper alternative that has the same limit distribution\nGrumps-style maximum likelihood, i.e Grumps without penalty\nditto, but imposing share constraints\nGMM estimator that uses both micro and macro moments and uses quadrature instead of Monte Carlo draws in the micro moments.  The micro moments are `smart' in that they condition on z_im instead of integrating it out.\na mixed logit estimator\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimator-Tuple{Symbol}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: Symbol )\n\nCreates and returns a GrumpsEstimator type.\n\nThis is one method of specifying the estimator used.  However, it is unforgiving in that the exact symbol used internally must be passed, so the Estimator( s :: String ) method is usually a better choice.\n\nPossible choices include:\n\n:pml the full Grumps maximum likelihood estimator  \n\n:cheap an alternative with the same limit distribution that is faster to compute\n\n:vanilla the unpenalized Grumps maximum likelihood estimator\n\n:shareconstraint the unpenalized Grumps maximum likelihood estimator with share constraints\n\n:gmm GMM estimator that uses both micro and macro moments\n\n:mixedlogit mixed logit maximum likelihood estimator\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimators-Tuple{}","page":"User interface","title":"Grumps.Estimators","text":"Estimators( elaborate = false )\n\nPrints a list of available estimators.  The argument indicates whether a lot of features should be printed  or few.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Choice-of-integration-method-(integrators)","page":"User interface","title":"Choice of integration method (integrators)","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps uses separate integration methods for the micro and macro components. The default choices are simple with small numbers of nodes and draws. For micro, it is Hermitian quadrature, for macro it's Monte Carlo draws. One gets the defaults if the choices are omitted.  The defaults chosen here are small in the sense that they emphasize speed / storage over accuracy.   To change the number of nodes or draws, simply call BothIntegrators with as argument(s), whichever of the two you wish to change.  For instance, integ = BothIntegrators( DefaultMicroIntegrator( 19 ) ) uses the default micro integrator with 19 nodes per dimension and the default macro integrator with the default number of draws.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The procedure is to create the integrators using a call to BothIntegrators with the desired integrators as arguments and then pass this in your call to Data.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"BothIntegrators( :: MicroIntegrator{T}, ::MacroIntegrator{T} ) where {T<:AbstractFloat}\nDefaultMicroIntegrator( ::Int, ::Type )\nDefaultMacroIntegrator( ::Int, ::Type )\nMSMMicroIntegrator( :: Int, ::Type )","category":"page"},{"location":"objects/#Grumps.BothIntegrators-Union{Tuple{T}, Tuple{MicroIntegrator{T}, MacroIntegrator{T}}} where T<:AbstractFloat","page":"User interface","title":"Grumps.BothIntegrators","text":"BothIntegrators( microIntegrator :: MicroIntegrator{T}, macroIntegrator :: MacroIntegrator{T} )\n\nCreates the type BothIntegrators containing both the indicated microIntegrator and macroIntegrator.  \n\nEither argument can be omitted.  If both arguments are omitted then one can pass the floating point type T instead.  If no floating point type is passed then a Float64 is assumed.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMicroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMicroIntegrator","text":"DefaultMicroIntegrator( n :: Int, T :: Type; options = nothing )\n\nCreates a basic quadrature Integrator using n nodes in each dimension.  Type T can be omitted, in which case it is Float64. The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMacroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMacroIntegrator","text":"DefaultMacroIntegrator( n :: Int, T :: Type; options :: Union{Vec{Symbol}, Nothing} = nothing )\n\nCreates a basic Monte Carlo Integrator using n draws.  Type T can be omitted, in which case it is Float64. The optional options argument can be used to indicate two possible changes from the default, namely :randomize can be used to require randomization and :replacement to indicate randomization with  replacement.  Note that options is either nothing or a vector of symbols.  The default for both is false.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.MSMMicroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.MSMMicroIntegrator","text":"MSMMicroIntegrator( n :: Int, T = F64; options = nothing )\n\nCreates a Monte Carlo integrator type for micro integration with GMM with smart moments.  The optional type can be omitted. The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/","page":"User interface","title":"User interface","text":"warning: Default macro integrator options\nBy default, the default macro integrator uses Monte Carlo integration with R = 10000 draws unless otherwise specified.  If one does not specify randomization then the default macro integrator simply uses the first R lines of draws for each market for demographics (z draws) and combines them with R draws from the distribution of the random coefficients (nu draws), both of which are then interacted with the product level regressors (x variables).  If the spreadsheet does not contain enough rows corresponding to a market then the program will cycle and throw a warning.  With randomization with replacement, R numbers are drawn from the draws spreadsheet regardless of the number of lines in the spreadsheet.  Without replacement, the same occurs and if the spreadsheet does not contain enough lines corresponding to the market, all lines are added and then the procedure is repeated.  In other words, there is replacement by necessity.  Again, a warning will be displayed. With randomization, the random numbers are drawn separately for each market.","category":"page"},{"location":"objects/#Data-object-creation","page":"User interface","title":"Data object creation","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The data stored in spreadsheets or other objects have to be converted into a form that Grumps understands.  The call to Data achieves that.   It takes as inputs the various choices made by the user and then creates an appropriate data object that is subsequently passed to the optimization call.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Data()","category":"page"},{"location":"objects/#Grumps.Data-Tuple{}","page":"User interface","title":"Grumps.Data","text":"Data( \n    e                   :: GrumpsEstimator,\n    ss                  :: Sources,\n    v                   :: Variables,\n    integrators         :: GrumpsIntegrators = BothIntegrators(),\n    T                   :: Type = F64,\n    options             :: DataOptions = GrumpsDataOptions(),\n    threads             :: Int = 0,\n    id                  :: Symbol = :default\n    )\n\nTakes user inputs and converts them into an object that Grumps can understand.  This is synonymous with GrumpsData(...).\n\nData takes the following arguments, of which the first three are mandatory:\n\ne:                   estimator; see Estimator\nss:                  cata sources; see Sources\nv:                   variables to be used; see Variables\no:                   optimization options to be used   \nintegrators:         see BothIntegrators, DefaultMicroIntegrator, and DefaultMacroIntegrator\nT:                   floating point type; not heavily tested\nu:                   not yet implemented\noptions:             data options to be used, see DataOptions\nthreads:             the number of parallel threads to be used in creating data\n\n\n\n\n\n","category":"method"},{"location":"objects/#Algorithm-call","page":"User interface","title":"Algorithm call","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Once all data structures have been put together, one can call the algorithm.  This is straightforward.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"    grumps!( ::Estimator, ::Data{T}, ::OptimizationOptions, ::Grumps.StartingVector{T}, ::StandardErrorOptions ) where {T<:Grumps.AbstractFloat}","category":"page"},{"location":"objects/#Grumps.grumps!-Union{Tuple{T}, Tuple{Estimator, Data{T}, OptimizationOptions, Union{Nothing, Vector{T}}, StandardErrorOptions}} where T<:AbstractFloat","page":"User interface","title":"Grumps.grumps!","text":"grumps!( \n    e       :: Estimator,\n    d       :: Data{T},\n    o       :: OptimizationOptions = OptimizationOptions(),\n    θstart  :: StartingVector{T} = nothing,\n    seo     :: StandardErrorOptions = StandardErrorOptions()\n)\n\nConducts the optimization.  You typically just want to set θstart to nothing, i.e. have a starting vector  picked automatically.  \n\n\n\n\n\n","category":"method"},{"location":"objects/#Retrieving-results","page":"User interface","title":"Retrieving results","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"As noted above, Grumps will return its results in a GrumpsSolution variable that can be queried or saved as follows.  You can also simply call one of the print or  related functions on any of these objects.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Finally, you can call any of minimum, iterations, iteration_limit_reached, converged, f_converged, g_converged, x_converged, f_calls, g_calls, h_calls, f_trace, g_norm_trace, x_trace on a GrumpsSolution or a GrumpsConvergence object in the same way that you would query the return value in the Optim package, albeit that they are not in the namespace by default so use Grumps.converged instead of converged.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"getθ( sol :: GrumpsSolution )\ngetδ( sol :: GrumpsSolution )\ngetβ( sol :: GrumpsSolution )\ngetcoef( e :: GrumpsEstimate )\ngetstde( e :: GrumpsEstimate )\ngettstat( e :: GrumpsEstimate )\ngetname( e :: GrumpsEstimate )\ngetθcoef( sol :: GrumpsSolution )\ngetδcoef( sol :: GrumpsSolution )\ngetβcoef( sol :: GrumpsSolution )\nSave( fn :: AbstractString, mt :: MimeText, x :: Any; kwargs... )\nSave( fn :: AbstractString, x :: Any; kwargs... )\nshow( io :: IO, e :: GrumpsEstimate{T}, s :: String = \"\"; adorned = true, printstde = true, printtstat = true ) where {T<:AbstractFloat}\nshow( io :: IO, est :: Vector{ GrumpsEstimate{T} }, s :: String = \"\"; adorned = true, header = false, printstde = true, printtstat = true ) where {T<:AbstractFloat}\nshow( io :: IO, convergence :: Grumps.GrumpsConvergence{T}; header = false, adorned = true ) where {T<:AbstractFloat}\nshow( io :: IO, sol :: GrumpsSolution{T}; adorned = true, printθ = true, printβ = true, printδ = false, printconvergence = true ) where {T<:AbstractFloat}\nshow( io :: IO, mt :: MimeTex, sol :: GrumpsSolution; kwargs... ) \nshow( io :: IO, mt :: MimeCSV, sol :: GrumpsSolution; kwargs... ) ","category":"page"},{"location":"objects/#Grumps.getθ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getθ","text":"getθ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for θ that can be queried for results.  See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getδ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getδ","text":"getδ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for δ that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getβ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getβ","text":"getβ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for β that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getcoef-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getcoef","text":"getcoef( e :: GrumpsEstimate )\n\nReturns the estimated coefficient value.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getstde-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getstde","text":"getstde( e :: GrumpsEstimate )\n\nReturns the standard error.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.gettstat-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.gettstat","text":"gettstat( e :: GrumpsEstimate )\n\nReturns the t statistic.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getname-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getname","text":"getname( e :: GrumpsEstimate )\n\nReturns the variable name.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getθcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getθcoef","text":"getθcoef( sol :: GrumpsSolution )\n\nReturns a vector of θ coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getδcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getδcoef","text":"getδcoef( sol :: GrumpsSolution )\n\nReturns a vector of δ coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getβcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getβcoef","text":"getβcoef( sol :: GrumpsSolution )\n\nReturns a vector of β coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Save-Tuple{AbstractString, Union{MIME{Symbol(\"text/tex\")}, MIME{Symbol(\"text/csv\")}, MIME{Symbol(\"text/plain\")}}, Any}","page":"User interface","title":"Grumps.Save","text":"Save( fn, mt, sol :: GrumpsSolution; keywords... )\n\nSaves the solution stored in sol to a file with filename fn which has mime type mt.  \n\nThere are several keywords that are described below, some of which will be ignored for some mime types.  Allowed mime types are text/plain, text/csv, and text/tex.\n\nKeyword Description Default\ncolsep column separator \",\"\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Save-Tuple{AbstractString, Any}","page":"User interface","title":"Grumps.Save","text":"Save( fn, sol :: GrumpsSolution; keywords... )\n\nThe same as the form of Save with prespecified mime type except that the mime type is now inferred from the file extension.  The keywords also have the same meaning, namely...\n\nThere are several keywords that are described below, some of which will be ignored for some mime types.  Allowed mime types are text/plain, text/csv, and text/tex.\n\nKeyword Description Default\ncolsep column separator \",\"\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsEstimate{T}}, Tuple{IO, GrumpsEstimate{T}, String}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, e :: GrumpsEstimate{T}, s :: String = \"\"; keywords...)\n\nShow a GrumpsEstimate object on io; the argument s indicates which parameter family (θ,β,δ) the estimate belongs to.  The optional keywords are described in the table below.\n\nKeyword Description Default\nadorned make output pretty? true\nprintstde print standard errors? true\nprinttstat print t statistics? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, Array{GrumpsEstimate{T}, 1}}, Tuple{IO, Array{GrumpsEstimate{T}, 1}, String}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, est :: Vector{ GrumpsEstimate{T} }, s :: String = \"\"; keywords... )\n\nShows a vector of estimates on io using the string s (typically one of θ,β,δ).  The command takes the following optional keywords.\n\nKeyword Description Default\nadorned make output pretty? true\nprintstde print standard errors? true\nprinttstat print t statistics? true\nheader descriptive header? false\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsConvergence{T}}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, convergence :: GrumpsConvergence{T}; keywords...)\n\nShows the contents of convergence, where the flags indicated what should be printed and how, as indicated in the following table.\n\nKeyword Description Default\nadorned make output pretty? true\nheader descriptive header? false\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsSolution{T}}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, sol :: GrumpsSolution{T}; keywords... )\n\nShows the contents of sol, where the keywords indicate what should be printed and how, as described in the table below.\n\nKeyword Description Default\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Tuple{IO, MIME{Symbol(\"text/tex\")}, GrumpsSolution}","page":"User interface","title":"Base.show","text":"show( io :: IO, mt :: MIME{Symbol(\"text/tex\")}, sol :: GrumpsSolution; keywords... )\n\nThis is the same as Save() except that the contents are spit out on io (which could be stdout or an already opened file).\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Tuple{IO, MIME{Symbol(\"text/csv\")}, GrumpsSolution}","page":"User interface","title":"Base.show","text":"show( io :: IO, mt :: MIME{Symbol(\"text/csv\")}, sol :: GrumpsSolution; keywords... )\n\nThis is the same as Save() except that the contents are spit out on io (which could be stdout or an already opened file).\n\n\n\n\n\n","category":"method"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Saving results to LaTeX\nTo save estimation results directly to a LaTeX tabular, just use a .tex extension in the filename.  For instance, write Save( \"results.tex\", sol ) if your solution is in the variable sol.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Saving output printed to terminal\nTo save the terminal output to html, one can use Aha, the Ansi HTML Adapter, which is a small program (unrelated to Julia) that converts terminal output to html.  The way that would work on Linux and Mac (after successful installation) if one ran Grumps directly from the command line is to append | aha > myrun.html, e.g. julia -t auto myprogram.jl | aha > myrun.html.","category":"page"},{"location":"extending/#Extending-Grumps","page":"Extending Grumps","title":"Extending Grumps","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Grumps can be extended in multiple ways.  Below three possibilities are discussed, namely using an existing estimator for a different data format, introducing a new estimator, and introducing a new integrator.","category":"page"},{"location":"extending/#examining-output-at-each-iteration","page":"Extending Grumps","title":"examining output at each iteration","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"On each iteration of both the inner and outer optimization steps, Grumps calls a callback function.  By default the callback for the inner optimization does nothing and the callback for the outer optimization prints a summary of progress.  Users can add to this by defining their own callback functions named δcallback and θcallback respectively.  These are called before Grumps continues with its own callback routine.  ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"To do this, one has to pass an id to OptimizationOptions() and define a callback that is specifically for this id.  The id should be a symbol, i.e. a word preceded by a colon.  For instance, one can specify id = :myid and define the callback","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function Grumps.θcallback( ::Val{ :myid }, statevec, e, d, o, oldx, repeatx, solution ) \n\n        println( \"hi\" )\n        \n    end","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Then include o = OptimizationOptions(; id = :myid ) (possibly with other options) in the program and pass o as an argument to grumps!.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This will print \"hi\" on every θ iteration.  The first argument of Grumps.θcallback specifies which id this callback refers to (in case there is more than one), statevec is the state vector of the Optim package (see the documentation of that package for details), oldx is the θ-vector value of the previous iteration, and repeatx is a single element vector that indicates how often the same value of the parameter vector has been repeated.  Messing with the values of the arguments is not recommended.  The Grumps.δcallback function has the same syntax but lacks the solution argument.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"If the id variable is set but no user callbacks are defined then Grumps will only execute the default callbacks.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"note: Do not overuse Grumps.δcallback\nIf one has many markets then the δ callback is called a lot. Be prepared for a lot of output.  The θ callback is not called nearly as often.","category":"page"},{"location":"extending/#using-a-new-data-format","page":"Extending Grumps","title":"using a new data format","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The format of Grumps is limited to specifications that are linear in parameters.  This cannot be altered.  The way that data are entered moreover presumes that there are only interactions of demographics and product level variables, interactions of random coefficients and product level variables, product level regressors (where product level regressors can include a constant), a quality variable xi, and an error term epsilon.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This can be changed, however.  Pretty much all methods that Grumps uses to create data take an input parameter named id.  This corresponds to the id set in DataOptions(), which is :Grumps by default.  This id can be set to any other symbol.  For instance, if one set id to :myid then one could add any of the methods taking an id in any of the Julia code files in src/common/data with one's own version.  For instance, the following method is defined in micro.jl:","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function CreateInteractions( id ::Any, dfc:: AbstractDataFrame, dfp:: AbstractDataFrame, v :: Variables, T = F64 )\n        MustBeInDF( v.interactions[:,1], dfc, \"consumer data frame\" )\n        MustBeInDF( v.interactions[:,2], dfp, \"product data frame\" )\n\n        S = nrow( dfc )\n        J = nrow( dfp ) + 1\n        dθz = size( v.interactions, 1 )\n        Z = zeros( T, S, J, dθz )\n        for t ∈ 1:dθz, j ∈ 1:J-1, i ∈ 1:S\n            Z[i,j,t] = dfc[i, v.interactions[t,1] ] * dfp[j, v.interactions[t,2] ]\n        end\n        return Z\n    end","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"If one now defines a new method in one's own code with ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function Grumps.CreateInteractions( ::Val{ :myid }, dfc, dfp, v, T )\n        ...\n        ...\n        ...\n    return Z\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"then Grumps will call the newly minted method instead of the default one.  But note that one would also need to adjust the corresponding macro integration part for estimators that use both micro and macro likelihoods.  For any functions for which no user-defined methods corresponding to the given id are defined, the default method is called.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"note: hogs and ants\nBy default, Grumps saves on storage by storing macro draws and regressors separately (:Ant mode for macro).  If one wanted a regressor that could not be expressed as e.g. the product of a demographic variable and a product variable, then the functions FillAθ! and FillZXθ! in src/common/probs/index.jl may need to have new methods added, also, if one wants to continue using :Ant mode.  An alternative for small problems is to switch to :Hog mode for the macro likelihood (the micro likelihood uses :Hog mode by default).","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"warning: two ids\nThere is one id for data creation passed in DataOptions() and one id for the optimization process passed in OptimizationOptions().  These ids can be different, but in most instances it is better to set these to the same value.  Note that the id used in FillAθ! and FillZXθ! is the optimization process id, not the data storage id.","category":"page"},{"location":"extending/#adding-a-new-estimator","page":"Extending Grumps","title":"adding a new estimator","text":"","category":"section"},{"location":"extending/#estimator-definitions","page":"Extending Grumps","title":"estimator definitions","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"A new estimator can be added by creating a new folder in the estimators folder.  By creating the folder, Grumps will automatically try to load an eponymous Julia file in that folder every time Grumps is run.  For instance, in src/estimators/pml you see a file pml.jl, which loads all Julia files in the folder other than description.jl. The file description.jl is loaded separately and automatically. ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The symbol used for the new estimator will correspond to the folder name.  For instance, if the folder name is foo then the new estimator symbol will be :foo.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The file description.jl should contain exactly two functions: name and Description.  It suffices to copy the description.jl file from another estimators folder and changing the particulars for your estimator.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For instance, the pml folder contains the file description.jl with contents","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"name( ::Val{:pml} ) = \"Grumps Penalized MLE\"\n\nfunction Description( e :: Symbol, v ::Val{ :pml } )\n    @ensure e == :pml \"oops!\"\n    return EstimatorDescription( e, name( Val( :pml ) ), \n      [ \"grumps\", \"pmle\", \"grumps penalized mle\", \"penalized likelihood\", \"grump\ns penalized maximum likelihood\", \"pml\", \"penmaxlik\" ]\n      )\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"All you need to do here is to change all the :pml entries to :foo, to change the return value of name to \"Foo Estimator\" and the array of strings in the return value of Description to a list of descriptors of your estimation method that define it clearly and set it apart from other estimators.  Make sure that none of the descriptors are used by other estimators.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"In a file loaded by foo.jl, preferably types.jl, one should define some properties of the estimators. In addition, there is a type associated with your estimator. For instance, the file types.jl in the pml folder contains","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"struct GrumpsPMLEstimator <: GrumpsPenalized\n    function GrumpsPMLEstimator() \n        new()\n    end\nend\n\nname( ::GrumpsPMLEstimator ) = name( Val( :pml ) )\n\ninisout( ::GrumpsPMLEstimator ) = true\n\nEstimator( ::Val{ :pml } ) = GrumpsPMLEstimator()","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The estimator type GrumpsPMLEstimator is used to allow Grumps to use the same function name with the estimator type to call different methods.  Note that GrumpsPMLEstimator is a subtype of GrumpsPenalized, which is done to allow for a single function call with different estimator type argument to select a method for all estimators that are subtypes of GrumpsPenalized.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For example, if one calls a function with an estimator type (and other arguments) then there is a default method that will be called unless there is a method defined for the desired supertype (e.g. GrumpsPenalized), which will be called unless there is a method defined for the exact estimator type (e.g. GrumpsPMLEstimator).","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For instance, the outer objective functions are all called ObjectiveFunctionθ! but which one is used depends on the estimator supertype.  For GrumpsPenalized it is the one in src/common/optim/objpml.jl.  Note that you can define different objective functions depending on e.g. the GrumpsData type that is passed, also.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For the new estimator :foo the name and Estimator methods in the above file can be changed by replacing :pml with :foo and PML with Foo everywhere, assuming that the new estimator type is GrumpsFooEstimator.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The final entry in types.jl is the line  inisout( ::GrumpsPMLEstimator ) = true What this line does is to tell Grumps that the objective function value in the inner optimization problem is the same as that in the outer optimization problem.  This is true for most estimators, but not for e.g. the share constraint estimator.  There are a number of properties like this (type Estimators(true) in the REPL to see them all), whose default values are in src/common/types/est.jl.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Now, the :vanilla (the Grumps estimator with exact identification in the product level moments) and :shareconstraint (ditto, but where the inner optimization runs maximizes only the macro likelihood) computations differ only in the contents of the theta.jl and delta.jl files.  In this case, the theta.jl files produce the single market outer objective function contributions and its first two derivatives and delta.j does ditto for the inner objective functions.","category":"page"},{"location":"extending/#Data-types","page":"Extending Grumps","title":"Data types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"There are several predefined Data types, which can be found in src/common/types/data.jl.  For instance, GrumpsData contains a vector of GrumpsMarketData objects (one for each market), a GrumpsPLMData object, and some other things.  GrumpsPLMData is for the penalty term.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Each GrumpsMarketData object contains a GrumpsMicroData object and a GrumpsMacroData object, one for the micro portion of the likelihood, and one for the macro portion of the likelihood.  These are themselves supertypes, so you can use/require whichever subtype you desire for your estimator, but if one of the existing ones suffices then use that.","category":"page"},{"location":"extending/#FGH-types","page":"Extending Grumps","title":"FGH types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"FGH types contain the objective function and its derivatives.  These can be by market or apply to (or contain results for) a number of markets.  If inisout returns true then the inner and outer objective FGH objects are physically the same.","category":"page"},{"location":"extending/#Space-types","page":"Extending Grumps","title":"Space types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Grumps preallocates space for choice probabilities and related objects and reuses their values where possible.  This saves computation time.  In most instances, the space types provided will suffice.","category":"page"},{"location":"extending/#adding-an-integrator","page":"Extending Grumps","title":"adding an integrator","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"to be done","category":"page"},{"location":"quickstart/#Quick-Start-Guide","page":"Quick start","title":"Quick Start Guide","text":"","category":"section"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To use Grumps.jl consider the following program, which computes the penalized maximum likelihood estimator of Grieco, Murry, Pinkse, and Sagl.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"using Grumps\n\n\n\nfunction myprogram(  )\n\n    @info \"setting source files\"\n    s = Sources(\n        consumers = \"example_consumers.csv\",\n        products = \"example_products.csv\",\n        marketsizes = \"example_marketsizes.csv\",\n        draws = \"example_draws.csv\"  \n    )\n    println( s )\n\n     v = Variables(\n        interactions =  [\n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        randomcoefficients =  [:ibu; :abv],\n        regressors =  [ :constant; :ibu; :abv ],\n        instruments = [ :constant; :ibu; :abv; :IVgh_ibu; :IVgh_abv ],\n        outsidegood = \"outside\"\n    )\n    println( v )\n\n    e = Estimator( \"pml\" )\n\n    d = Data( e, s, v )\n\n    sol = grumps!( e, d )\n\n    println( sol )\n\n    Save( \"myresults.csv\", sol )\nend\n\nmyprogram()","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To see what is happening in the code, consider the function myprogram.  It first describes where data on consumers, products, market sizes, and random draws can be found.  This happens in the Sources call. In this example, all sources are files, but DataFrames are ok, also.  In addition, not all sources are needed for all estimators and options.  Indeed, only products data are required.  See Spreadsheet formats for documentation on the spreadsheet formats.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Next, in Variables it describes what variables to include. There are two different but equivalent versions of this method: the only difference is the syntax to accommodate users' preferences.  The example here covers only one version. In this case, there are three interactions between demographic characteristics (in the first column) and product characteristics (in the second column).  There are moreover random coefficients on the ibu and abv variables.  The product-level regressors and instruments that go into hat Pi are also entered.  Finally, the outsidegood argument indicates which value in the consumers spreadsheet is used to indicate that a product is the outside good.  There are many other choices; please see the User Interface section.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"tip: Objects can be printed\nMost variables with data types created by Grumps can be printed.  For instance, the println( v ) line tells Grumps to print the variable v, which in this case contains information about the specification. println( d ) works too after the Data call.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"It then tells Grumps that it wants to use the full Grumps maximum likelihood estimator with penalized deviations from the macro moments in Estimator.  You could also have entered another descriptive string; Grumps is pretty good at figuring out what you want.  Or you can use a symbol, like :mle.  In the Data call, it reads the data needed from the sources indicated in the Sources call using the information specified in the Variables call.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"The grumps! call then asks Grumps to compute the estimates.  The exclamation mark (bang) signifies that grumps! can change its arguments, including the starting value.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Finally, Save saves the results to disk, in this case to a CSV file, but other formats are possible, also.  And the results can of course be printed, also, as the above program demonstrates.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Note that there are many other options and calls.  The main ones are described in the User Interface tab.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"tip: Getting help\nTo get help on a command, simply load Grumps in the REPL and type e.g.julia> ?Variables","category":"page"},{"location":"spreadsheet/#Spreadsheet-formats","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Recall that Grumps can take data from four different sources and in different formats.  Currently, only CSV files and DataFrames are implemented.  Recall that not all four sources are required for all estimators.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"tip: Files are preferable to dataframes\nThere is one advantage to providing file names instead of dataframes, and that is that Julia can release the memory allocated by the memory after return of the Data call.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"As mentioned elsewhere, there is one spreadsheet (the products spreadsheet) that contains data on products, including e.g. price, market share, features, product level instruments (sxb in the paper).  If consumer data are used then such data can be entered via the consumers spreadsheet, which includes data on individual consumer choices, demographic characteristics, etcetera: anything that would typically have an i subscript in other words (yz in the paper).  A market size spreadsheet would contain information on the size of each market, i.e. the population in that market, which is only needed if the macro portion of the likelihood is to be used (N in the paper).  Finally, a demographic draws spreadsheet can be provided to be used in the macro likelihood portion of the objective function, i.e. z draws to use in the macro integration.  The format of each of these spreadsheets is described below.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"In the examples below, the data are comma separated, but that is not necessary: other formats can be specified in the Sources call.  Column ordering is irrelevant.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"warning: Cases and spaces\nFor all spreadsheets be mindful of case and spaces.  That means omit spaces and be consistent in lower case versus upper case. For readability the spreadsheets below contain extra space i.e. they are aligned by comma; this is not advisable.  ","category":"page"},{"location":"spreadsheet/#Product-characteristics","page":"Spreadsheet formats","title":"Product characteristics","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"ibu ,  abv, share, IVgh_ibu, IVgh_abv, IVj_ibu, IVj_abv, market  , product\n1.09, 1.01, 0.01 , 12.57   , 11.45   , 4.78   , 5.09   , market 1, product 1\n2.85,-0.10, 0.13 , 10.52   ,  8.55   , 5.21   , 5.23   , market 1, product 2\n2.31, 0.55, 0.02 , 4.54    ,  7.26   , 5.91   , 5.52   , market 1, product 3","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The column headings are variable names.  Each line corresponds to a (market, product) pair and both these columns are required, albeit that the columns can have different names; market and product are just the defaults.  The markets have especially boring names in this example, but any string goes.  The same is true for products.  This spreadsheet does not need to include the outside good (indeed, leave it out) and shares would thus typically sum to a number less than one.  Which columns are to be used and where is  determined by the Variables call.  To use dummy variables, just insert a column with the corresponding characteristics (there can be multiple categories, which can be descriptive (e.g. strings)), which Grumps can turn into dummy variables automatically, as described in the Variables documentation.","category":"page"},{"location":"spreadsheet/#Consumer-characteristics","page":"Spreadsheet formats","title":"Consumer characteristics","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"income,  age, purchase, second,   market,     choice\n -1.20, 1.24,        8,     11, market 1,  product 8\n -0.64, 0.36,       11,      8, market 1, product 11\n -0.65, 1.32,        4,      3, market 1,  product 4\n -0.82, 0.77,       11,      4, market 1, product 11","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The columns are again variable names.  Here, we need both market and choice, but the columns do not have to have those (default) headings.  Indeed, choice could have been replaced with purchase, and nothing would have been different, albeit that the same product and market descriptors should be used across data sources (spreadsheets).  The markets and products could have had more descriptive names (e.g. \"Pennsylvania\" instead of \"market 1\"), and the column headings could have been different.","category":"page"},{"location":"spreadsheet/#Market-sizes","page":"Spreadsheet formats","title":"Market sizes","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"N     , market\n100000, market 1\n100000, market 2\n100000, market 3\n100000, market 4\n100000, market 5","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Note that there is one line per market.  Again, the column headings can be adjusted and the ones presented here are the default ones.","category":"page"},{"location":"spreadsheet/#Draws","page":"Spreadsheet formats","title":"Draws","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"income,  age, market\n -1.60, 1.19, market 1\n -2.93, 1.23, market 1\n -1.78, 1.58, market 1\n -1.14, 1.70, market 1","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The format and limitations for the draws spreadsheets is essentially the same as the other spreadsheets, but here each line corresponds to a (draw,market) pair. For markets for which market size information is available, one typically needs a number of demographic draws no less than the number of Monte Carlo draws to be used, where each draw is a vector of demographic characteristics that would be observed in the micro sample.  ","category":"page"},{"location":"structure/#Directory-structure","page":"Directory structure","title":"Directory structure","text":"","category":"section"},{"location":"structure/#Top-level-folders","page":"Directory structure","title":"Top level folders","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"There are really two folders with sources:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"src for the programs\ndocs for the documentation","category":"page"},{"location":"structure/#src-folder","page":"Directory structure","title":"src folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Within src you will find the main package file Grumps.jl plus includes.jl, which loads all source code, and exports.jl which contains all exported symbols, i.e. symbols that you can use directly in your program without prefacing it with Grumps..","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Beyond that, you will find several folders in src:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"packages: loads all packages\ncommon: loads code that is common to several estimators\nestimators: code that is specific to one estimator\nintegrators: code that is specific to one integrator","category":"page"},{"location":"structure/#common-folder","page":"Directory structure","title":"common folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Within common there are a number of folders depending on the role they play in the program.  These are listed below.  ","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"array utilities for dealing with arrays\ndata data handling\nearly code that should be read and processed before other code\nerror error handling\nest code that gets called to compute estimators\nimports imports from other packages, mostly Base\ninference standard errors and such\nintegration numerical integration\nio reading data from and to files\noptim optimization\nprobs computation of choice probabilities\nsol handling solution object\nspace dealing with objects that reserve space ahead of time\nthreads multithreading objects\ntree contains code to print object types\ntypes contains code that defines object types\nutils contains miscellaneous utilities","category":"page"},{"location":"structure/#estimators-folder","page":"Directory structure","title":"estimators folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"The estimators folder contains a number of folders, one per estimator.  Each folder corresponds to a specific estimator.  For instance, pml contains code specific to the main Grumps estimator.","category":"page"},{"location":"structure/#integrators-folder","page":"Directory structure","title":"integrators folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"The integrators folder contains folders, one per integration method, for any integrators beyond the default integrators, which are handled under common.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"#Grumps.jl","page":"Home","title":"Grumps.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Grumps.jl is a package for computing random coefficients demand models, including:","category":"page"},{"location":"","page":"Home","title":"Home","text":"the conformant likelihood with exogeneity restrictions (CLER) estimator of Grieco, Murry, Pinkse, and Sagl (2022)\nan asymptotically equivalent less expensive alternative thereof\nthe unpenalized likelihood estimator of Grieco, Murry, Pinkse, and Sagl (2022)\nGMM type random coefficient models in the style of Berry, Levinsohn, and Pakes (2004)\nGMM type random coefficient models in the style of Berry, Levinsohn, and Pakes (1995)\nMixed logit models\nMultinomial logit models","category":"page"},{"location":"","page":"Home","title":"Home","text":"It can handle problems of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"(hatdeltahatthetahatbeta) = textargmin_deltathetabeta big( - log hat L(deltatheta) + hatPi(deltabeta) big)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where log hat L is the sum of a micro loglikelihood and a macro loglikelihood and hatPi is a quadratic penalty term.  Any of the three components can be omitted if so desired. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Typically, log hat L is a sum over markets, products, and consumers whereas hatPi is a GMM-style squared norm of a vector-valued sum over markets.  Please see Grieco, Murry, Pinkse, and Sagl (2022) for details.","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation describes the use of the Grumps computer package.  It does not describe the estimators or algorithms.  Please refer to Grieco, Murry, Pinkse, and Sagl (2022) for that.  In addition, the code itself is documented, also.","category":"page"},{"location":"#Limitations","page":"Home","title":"Limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is still a preliminary version of Grumps, so please advise Joris Pinkse of any bugs, problems, shortcomings, missing features, etcetera.  Features it does not currently possess include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"sparse quadrature or similar integration methods\ndistributed computing\nGPUs\nstatistics other than coefficients, e.g. elasticities\nintegration methods for the micro portion of the GMM estimator other than quadrature\ntraditional GMM; see Grieco, Murry, Pinkse, and Sagl (2022) for details\nstandard errors for some of the estimators\ndetailed sanity checks","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of this code is subject to the MIT license.  This code includes a modified version of the Newton Method with Trust Regions code in the Optim package, which is also subject to the MIT license.","category":"page"},{"location":"example/#Example-program","page":"Example program","title":"Example program","text":"","category":"section"},{"location":"example/","page":"Example program","title":"Example program","text":"Below is a documented example program.  You can find a closely related example program in the extras/example folder.","category":"page"},{"location":"example/","page":"Example program","title":"Example program","text":" # set relative path of location of Grumps.jl; won't be needed \n # once Julia is a formal package\npush!(LOAD_PATH, \"src\")                                                    \n\n\nusing Grumps\n\n\nfunction myprogram( nodes, draws, meth  )\n    # set which files contain the data to be used\n    s = Sources(                                                            \n      consumers = \"_example_consumers.csv\",\n      products = \"_example_products.csv\",\n      marketsizes = \"_example_marketsizes.csv\",\n      draws = \"_example_draws.csv\"  \n    )\n    \n    # set the specification to be used\n    v = Variables( \n        # these are the z_{im} * x_{jm} terms in the paper                                                         \n        interactions =  [                                                   \n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        # these are the x_{jm} * ν terms in the paper\n        randomcoefficients =  [:ibu; :abv],     \n        # these are the x_{jm} terms in the paper                            \n        regressors =  [ :constant; :ibu; :abv ],      \n        # these are the b_{jm} terms in the paper                      \n        instruments = [ :constant; :ibu; :abv; :IVgh_ibu; :IVgh_abv ], \n        # these are not needed for the estimators in the paper, just for GMM     \n        microinstruments = [                                                \n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        # this is the label used for the outside good\n        outsidegood = \"product 11\"                                          \n    )\n    \n    # these are the data storage options; since these are the defaults, \n    # this can be omitted\n    # dop = DataOptions( ;micromode = :Hog, macromode = :Ant, balance = :micro )  \n\n    # these are the defaults so this line can be omitted, albeit that the default \n    # number of nodes is small\n    # ms = DefaultMicroIntegrator( nodes ) \n    # these are the defaults so this line can be omitted, albeit that the default \n    # number of draws is small                                   \n    # Ms = DefaultMacroIntegrator( draws )                                    \n\n    # creates an estimator object\n    e = Estimator( meth )                                                     \n\n    # this puts the data into a form Grumps can process\n    d = Data( e, s, v ) \n    # there are longhand forms if you wish to set additional parameters\n    # d = Data( e, s, v, BothIntegrators( ms, Ms ); threads = 32 )            \n\n    # no need to set this unless you wish to save memory, will not exceed number \n    # of threads Julia is started with\n    # th = Grumps.GrumpsThreads( ; markets = 32 )                             \n\n    # redundant unless you wish to save memory\n    # o = Grumps.OptimizationOptions(; memsave = true, threads = th )         \n\n    # redundant unless you wish to have standard errors on objects other than β,θ \n    # seo = StandardErrorOptions(; δ = true )                                 \n\n    # compute estimates using automatic starting values\n    sol = grumps!( e, d )           \n    # long version to set more options                                          \n    # sol = grumps!( e, d, o, nothing, seo  )                                 \n    return sol\nend\n\n\nfor nodes ∈ [ 11 ] # , 17, 25]\n    for draws ∈ [ 10_000 ]  # , 100_000 ]\n        # other descriptive strings are allowed, as are the exact symbols\n        for meth ∈ [ \"grumps\", \"mle\", \"grumps share constraints\", \"mixed logit\", \"gmm\" ]         \n            @info \"$nodes $draws $meth\"\n            sol = myprogram( nodes, draws, meth ) \n            println( getθcoef( sol ), \"\\n\" )\n            println( sol, \"\\n\" )\n        end\n    end\nend","category":"page"}]
}
