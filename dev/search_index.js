var documenterSearchIndex = {"docs":
[{"location":"tutorial/#CLER-Tutorial-Using-Car-Data","page":"Charlie's tutorial","title":"CLER Tutorial Using Car Data","text":"","category":"section"},{"location":"tutorial/#Introduction","page":"Charlie's tutorial","title":"Introduction","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"This tutorial explains how to use the package Grumps.jl to estimate demand, as described in Grieco, Murry, Pinkse, Sagl (2023). Although we do not have the same exact data and we deviate from the empirical specification, the exercise is meant to mimic the data environment in Petrin (2002), who estimates the demand for new cars using aggregate data on national shares and prices, and consumer survey data from the Consumer Expenditure Survey.  You can find the data and code at  extras/charliestutorial","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"First, we describe the automobile data used for the tutorial and write a bit of Julia code to process the data so that it can be used by Grumps.   ","category":"page"},{"location":"tutorial/#Data","page":"Charlie's tutorial","title":"Data","text":"","category":"section"},{"location":"tutorial/#Data-Description","page":"Charlie's tutorial","title":"Data Description","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"The data were originally collected by Grieco, Murry, and Yurukoglu (2023) and are, collectively, a subset of the data used in that paper.  We use Wards Automotive product-level data from 1980-2005, which includes prices, quantities, and vehicle attributes.  The data file is called gmy_product.csv.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"We also use survey data from the automobile supplement to the Consumer Expenditures Survey from 1980–2005, where for each respondent we observe which car they purchased and various household characteristics.  The data file is called gmy_cex_consumer.csv.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"In order to simulate the population of potential buyers, we use demographics from the consumer expenditure survey for the same time frame. The raw CPS data file is called CPS_households.csv.  We will need to process this data a bit. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Lastly, there is data on market sizes.  This is in the data file called gmy_market.csv","category":"page"},{"location":"tutorial/#Data-Processing","page":"Charlie's tutorial","title":"Data Processing","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Let's start working with the data in Julia. First let's load all of the packages we will need.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"using Grumps\nusing Revise, CSV, LinearAlgebra, DelimitedFiles, Random\nusing DataFrames, DataFramesMeta\n\nRandom.seed!(16802)","category":"page"},{"location":"tutorial/#Process-the-CPS-data","page":"Charlie's tutorial","title":"Process the CPS data","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Next we will write a function to process the CPS data to make it look like the CEX survey data. In the end, these files should have identical variable names. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"function makeCPS(;numDraws=10_000)\n# Description: reads in raw CPS data, draws random sample, \n# and creates varaibles for estimation\n#\n# Inputs:\n# numDraws      | Number of random draws (optional, default = 10_000)\n\n@subset!(df_cps, :hhincome.>0)\n\nyears = 1980:2005\nnYrs = length(years)\ndf_draws = DataFrame()\nfor ix in years\n    df_tmp = df_cps[df_cps.year.==ix,[:year, :rural, :hhincome, :married, :numchildren, :age]]\n    sz = size(df_tmp)[1]\n    idx = rand(1:sz,10_000)\n    df_draws = vcat(df_draws, df_tmp[idx,:])\nend\n\n@transform!(df_draws, :urban = 1 .- :rural)\n@transform!(df_draws, :fam_size = 1 .+ :married .+ :numchildren)\n@transform!(df_draws, :income = :hhincome./10_000)\n@transform!(df_draws, :inc2 = :income.^2)\ndf_draws.log_inc = log.(df_draws.hhincome)\n\nCSV.write(\"gmy_draws.csv\",df_draws)\nend","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"This function reads in CPS_households.csv to a data frame, subsets to only positive incomes, then for each year draws 10,000 random people. Then it generates new variables to match with the CEX survey data and writes the new data to gmy_draws.csv.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Now let's just call this function to process the CPS data.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"makeCPS()","category":"page"},{"location":"tutorial/#Subset-the-data","page":"Charlie's tutorial","title":"Subset the data","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"We may want to run our estimation on datasets of different sizes, so next I create a function to subset the data for the final estimation run and saves them to separate files that we will later load with the estimation routine. The following function subsets the data in terms of markets (years) and the number of micro consumers we use from the survey data. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"function makeDataForEstimation(beg_year, end_year, num_cons=nothing)\n    # Description: Function to subset data\n    #\n    # Inputs:\n    # beg_year  | first year\n    # end_year  | last year\n    # num_cons  | number of micro consumers per year (optional, default=nothing)\n\n    # Consumer Sample\n    df_cons = CSV.read(\"gmy_cex_consumer.csv\",DataFrame)\n    @subset!(df_cons,:income.>0)\n    @transform!(df_cons, :log_inc = log.(:income))\n    @transform!(df_cons, :income = :income./10_000)\n    @transform!(df_cons, :inc2 = (:income).^2)\n    @subset!(df_cons, :year .>= beg_year)\n    @subset!(df_cons, :year .<= end_year)\n\n    if num_cons !== nothing        # Further subsets the consumer data (optional)\n        years = unique(df_cons.year)\n        df_new = DataFrame()\n        for ix in years\n            df_tmp = df_cons[df_cons.year.==ix,:]\n            sz = size(df_tmp)[1]\n            idx = rand(1:sz,num_cons)\n            df_new = vcat(df_new, df_tmp[idx,:])    \n        end\n        CSV.write(\"consumer.csv\",df_new)\n    else\n        CSV.write(\"consumer.csv\",df_cons)\n    end\n\n    # Products\n    df_prod = CSV.read(\"gmy_product.csv\", DataFrame)\n    @subset!(df_prod, :year .>= beg_year)\n    @subset!(df_prod, :year .<= end_year)\n    CSV.write(\"product.csv\", df_prod)\n\n    # Markets\n    df_market = CSV.read(\"gmy_market.csv\", DataFrame)\n    @subset!(df_market, :year .>= beg_year)\n    @subset!(df_market, :year .<= end_year)\n    CSV.write(\"market.csv\", df_market)\n    \n    # CPS draws\n    df_draws = CSV.read(\"gmy_draws.csv\", DataFrame)\n    @subset!(df_draws, :year .>= beg_year)\n    @subset!(df_draws, :year .<= end_year)\n    CSV.write(\"draws.csv\", df_draws)   \nend","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Run this function, specifying the years and that we only want 100 micro consumers oer year. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"makeDataForEstimation(1985,2000,100)","category":"page"},{"location":"tutorial/#Grumps-Package-Installation","page":"Charlie's tutorial","title":"Grumps Package Installation","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Grumps.jl is available from the Julia package repository. To add it to your installation","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"using Pkg\nPkg.add(\"Grumps\")","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Julia makes use of parallelization. To invoke Julia with 4 threads on your local machine (for example) invoke Julia in the following way.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"julia -t 4 \"myprog.jl\"","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"See the Installation and invocation page on the docs for more detail. ","category":"page"},{"location":"tutorial/#Estimation","page":"Charlie's tutorial","title":"Estimation","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Now we are ready to use Grumps.jl to estimate demand for cars. The way to call the estimator is through the following function call","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"sol = grumps!(e,d,o)","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"where e is the \"Estimator\" structure that tell Grumps which estimator to use, d is the \"Data\" structure that tells Grumps where the data is and which variables to use, and o is a \"Estimation Options\" structure that supplies various computation options to the program. The function call returns a structure that we have names sol.","category":"page"},{"location":"tutorial/#Estimator","page":"Charlie's tutorial","title":"Estimator","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"First, let's pick a estimator, e. The main estimator described in the paper is the :cler estimator. The code also implements is an alternative (and asymptotically equivalent) estimator called :cheap that uses less memory and should be faster. Other options are in the following table","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Estimator Description\n:cler main estimator described in the paper\n:cheap computationally cheaper version of :cler\n:mdle version of :cler without the product-level restrictions, hatPi\n:shareconstraint Further implements the BLP contraction mapping to get delta's\n:mixedlogit Uses only the likelihood of individual choices","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"We will implement :cler for the purposes of the tutorial. If this uses too much memory for you, switch to using the :cheap method.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"e = Estimator( :cler )","category":"page"},{"location":"tutorial/#Data-2","page":"Charlie's tutorial","title":"Data","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Now let's tell Grumps about our data. The data structure is formed by the following call:","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"d = Data( e, s, v ) ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"which takes e, the same \"Estimator\" object as above, s, a \"Sources\" object, and v, a \"Variables\" object. We tell Grumps where the data are located with the following source object. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"s = Sources(                                                            \n  consumers = \"consumer.csv\",\n  products = \"product.csv\",\n  marketsizes = \"market.csv\",\n  draws = \"draws.csv\"  \n)","category":"page"},{"location":"tutorial/#Variables","page":"Charlie's tutorial","title":"Variables","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Lastly, we can tell Grumps about the specification of the model, or which \"Variables\" to include. This can be a large object with many sub-structures because the model can be pretty complicated. ","category":"page"},{"location":"tutorial/#Demographic-Interactions","page":"Charlie's tutorial","title":"Demographic Interactions","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"List interactions between car attributes and demographic characteristics in the \"interactions\" sub-object. List the demographic variable first and the product attribute","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"v = Variables( \n    # these are the z_{im} * x_{jm} terms in the paper                                                         \n    interactions =  [                                                   \n        :log_inc :msrp; \n        :fam_size :van;\n        :urban :truck;\n        :log_inc :constant;\n        ],","category":"page"},{"location":"tutorial/#Random-Coefficients","page":"Charlie's tutorial","title":"Random Coefficients","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Next can specify the random coefficients. If you want more than one, you can separate them with a \";\".","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"    # these are the x_{jm} * ν terms in the paper\n    randomcoefficients =  [:log_mpg],","category":"page"},{"location":"tutorial/#Linear-Utility-Coefficients","page":"Charlie's tutorial","title":"Linear Utility Coefficients","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Next we can specify the product attributes that enter into the linear part of the utility and the instruments we will use as part of the product level exclusion restrictions. Notice how we inlcude price as a regressor but exclude it as an instrument. Here, we are including two instruments, so that the model in over-identified. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"    # these are the x_{jm} terms in the paper                            \n    regressors =  [ :constant; :log_mpg; :log_hp; :log_footprint; :log_curbweight; :suv; :van; :truck; :msrp],      \n    # these are the b_{jm} terms in the paper                      \n    instruments = [:constant; :log_mpg; :log_hp; :log_footprint; :log_curbweight; :suv; :van; :truck; :lag_pl_con; :IV1; :IV3], ","category":"page"},{"location":"tutorial/#Other-Variables","page":"Charlie's tutorial","title":"Other Variables","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Lastly there are other variables we have the option to specify in the model. We can tell Grumps what to call the outside good, what we call the market in our datasets (in the car data, a market is :year), what variable contains product shares (:share), and what variable denotes different products (:model in our case). Optionally, we can include a categorical variable that Grumps can include as dummies, and if there is a dummy variable that we want to control for, but we don't care about the coefficients, we can list that as a \"nuisancedummy.\" Here we include year and make effects, and we don't care about the make coefficients. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"    outsidegood   = \"outsidegood\",   \n    market          = :year,\n    share           = :share,\n    product         = :model,\n    dummies         = [:year],\n    # nuisancedummy   = :make # I don't have this in the data, but if I did...\n)","category":"page"},{"location":"tutorial/#Estimation-2","page":"Charlie's tutorial","title":"Estimation","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Now we could put everything we did to set up estimation into a function and call that function. It will have the following structure where the \"...\" is just a placeholder for the code in the blocks above. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"function my_estimation(nodes, draws, meth)\n    e = Estimator(meth)\n    s = Sources(...)\n    v = Variables(...)\n    d = Data(...)\n\n    sol = grumps!(e,d)  \nend\n\nnodes = 11\ndraws = 2_000\nmeth = :cheap\n\nsol = my_estimation(nodes, draws, meth)\n ```\n\nWe can use the \"Save\" feature of Grumps to write our solution structure to a text file. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"julia Grumps.Save(\"myresults_meth.txt\",sol) ```","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"If everything is in a .jl file, the we call the file from the command line, specifying the number of threads we would like to use. See the accompanying tutorial.jl file to see the finished result. Iterations on my laptop using six threads take about 200 seconds, so you'll have to wait a few minutes before you start seeing iteration output. ","category":"page"},{"location":"tutorial/#References","page":"Charlie's tutorial","title":"References","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Petrin, Amil. \"Quantifying the benefits of new products: The case of the minivan.\" Journal of political Economy 110, no. 4 (2002): 705-729.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Grieco, Paul and Murry, Charles and Pinkse, Joris and Sagl, Stephan. \"Conformant and Efficient Estimation of Discrete Choice Demand Models.\" working paper, Penn State University (2023).","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Grieco, Paul L. E., Charles Murry, and Ali Yurukoglu. “The Evolution of Market Power in the US Auto Industry.” Working Paper. Working Paper Series. National Bureau of Economic Research, July 2021. https://doi.org/10.3386/w29013.","category":"page"},{"location":"tutorial/#Appendix-A:-Description-of-Datasets","page":"Charlie's tutorial","title":"Appendix A: Description of Datasets","text":"","category":"section"},{"location":"tutorial/#gmy_product.csv","page":"Charlie's tutorial","title":"gmy_product.csv","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Unit of observation is a year-model.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Variable Type Description\nyear float year of sales / modelyear\nmodel int unique model ID (same model is same ID across years)\nshare float sales / market size\nmsrp float price of the the vehicle\nlog_footprint float car height in inches\nlog_curbweight float (p 50) curbweight\nlog_hp float horsepower\nlog_mpg float MPG rating (city or combined if city missing)\nregionUS float dummy: brand region is US (eg Chrysler is US, Fiat is EU)\nregionEU float dummy: brand region is EU (eg Chrysler is US, Fiat is EU)\nregionASIA float dummy: brand region is Asia\nEV float dummy: car is completely electric powered or a PHEV\nmake2num int vehicle make ID (smallest britsh makes combined into one)\nsuv int dummy: vehicle is SUV or CUV\ntruck int dummy: vehicle is a pickup truck\nvan int dummy: vehicle is a van\ncar float dummy: aggregate of sedan, couple, hatchback and other car styles\nlagplcon float lagged real exchage rate of production country\niv_prod int dummy: production country == hq country\nIV1 float number of products available for the same vehicle type\nIV2 float Ghandi-Houde IV for horsepower\nIV3 float GH IV for mpg\nIV4 float GH IV for footprint\nIV5 float GH IV for curbweight\nIV6 float number of products available for the same HQ region\nIV7 float number of products available for the same type and HQ region","category":"page"},{"location":"tutorial/#gmy_market.csv","page":"Charlie's tutorial","title":"gmy_market.csv","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Unit of observation is a year.","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Variable Type Description\nyear int year of sales / modelyear\nN float Total number of US household that year, Census (unit of obs: year)","category":"page"},{"location":"tutorial/#gmy*cex*consumer.csv","page":"Charlie's tutorial","title":"gmycexconsumer.csv","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Unit of observation is a suvey response. A survey takes place in a single year, and always includes a choice of a car. ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Variable Type Description\nyear int year of sales / modelyear\nchoice int model ID corresponsing to purchase decision\nincome float househild income\nfam_size int number of household members\nurban int dummy: 1 if the household location is urban.","category":"page"},{"location":"tutorial/#gmy_draws.csv","page":"Charlie's tutorial","title":"gmy_draws.csv","text":"","category":"section"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Unit of observation is a survey response. A survey takes place in a single year. These are population draws from the Consumer Population Survey.  ","category":"page"},{"location":"tutorial/","page":"Charlie's tutorial","title":"Charlie's tutorial","text":"Variable Type Description\nyear int year of sales / modelyear\nweight float CPS sampling weights.\nrural int dummy: household in non-urban location\nhhincome float househild income\nmarried int dummy: 1 if respondent married\nnumchildren int number of children in household\nother variables not used  ","category":"page"},{"location":"installation/#Installation-and-invocation","page":"Installation","title":"Installation and invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"First, ensure that you have Julia version 1.8 or later installed.  Julia can be downloaded from Julia downloads page.  Grumps will not work with older versions of Julia.","category":"page"},{"location":"installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Package installation is achieved in the usual way, i.e. by typing ","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"\t]add Grumps","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"in the Julia  REPL.  ","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"note: For those unfamiliar with Julia:\nThe REPL is the environment that opens up if you start Julia without arguments or which you automatically get with virtual studio code, the preferred editor for Julia.So once you have started Julia, type the character ]: this will open the packaging system for you.  Then type add Grumps; this will install Grumps.  Finally, hit the backspace key to take yourself out of the packaging system again.","category":"page"},{"location":"installation/#Invocation","page":"Installation","title":"Invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Fire up Julia using julia -t 4 replacing the number 4 with whatever number of threads you wish to use (or auto to automatically use all threads in your computer).  The recommended number is the number of physical cores in your computer, which is usually less than the total number of threads (often by a factor of two).  As a permanent solution, one can set the JULIA_NUM_THREADS environment variable.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Grumps can then be loaded with using Grumps.  That's it: you're ready to go.","category":"page"},{"location":"estimators/#Estimators","page":"Estimators","title":"Estimators","text":"","category":"section"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The text below describes the estimators that Grumps can compute.  To select one, refer to the Estimator choice section.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The estimator proposed by Grieco, Murry, Pinkse, and Sagl minimizes the sum hatOmega of three objective functions, (minus) a micro loglikelihood, (minus) a macro loglikelihood, and a GMM type quadratic objective function for the product level moments: see Grieco, Murry, Pinkse, and Sagl (2022) for details.  ","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"There are three parameter vectors to be estimated: betathetadelta.  Since beta can be easily estimated off delta and the data, the remainder of this discussion focuses on the estimation of thetadelta.","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"The full Grumps (CLER) estimator minimizes hatOmega over delta for a given theta in an inner loop and then minimizes over theta in an outer loop.     This is efficient, but costly. This estimator is labeled as :cler in the code. See Estimator( :: Symbol ).\nThe cheap Grumps (CLER)  estimator that is asymptotically equivalent but less expensive computationally. It only minimizes with respect to delta over minus the sum of the loglikelihoods in an inside loop and minimizes hat Omega over theta in the outside loop. This estimator is labeled :cheap in the code. \nThe mixed data likelihood estimator (MDLE), which drops the product level moments term in both the inside and outside loops.  This estimator is not conformant (see the paper for its definition) and is therefore inferior to each of the above two estimators. This estimator is labeled :mdle\nA fourth share constrained estimator maximizes the macro loglikelihood in the inside loop and the sum of the two loglikelihoods in the outside loop.  This  estimator is inferior to the MDLE. This estimator is labeled :shareconstraint in the code.\nA mixed logit, which would drop the macro loglikelihood entirely. This estimator is labeled :mixedlogit in the code. ","category":"page"},{"location":"estimators/","page":"Estimators","title":"Estimators","text":"Finally, there is an unfinished implementation of a moments estimator, which should not be used.","category":"page"},{"location":"flow/#Algorithm-flow","page":"Algorithm flow","title":"Algorithm flow","text":"","category":"section"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"(Image: algorithm flow)","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"When Grumps is called using the grumps! call, it runs the grumps! method in est.jl in the optim folder.  This sets up various objects and then calls an optimizer with an objective function that is estimator-specific.  In other words, it will call a different method depending on the e argument in ObjectiveFunctionθ! in est.jl in the optim folder.","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"These methods ObjectiveFunctionθ! are defined either in one of the Julia files in the optim folder whose name starts with obj, or in a specific estimator folder; see estimators folder.  ObjectiveFunctionθ! then decides which internal optimizer (i.e. one that finds delta) to call: they're all called grumpsδ!.","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"After optimization is completed, Grumps will call a standard error computation routine and then return.","category":"page"},{"location":"misc/#Miscellanea","page":"Miscellanea","title":"Miscellanea","text":"","category":"section"},{"location":"misc/#Reducing-data-load-times","page":"Miscellanea","title":"Reducing data load times","text":"","category":"section"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"Grumps uses three packages that have significant overhead when they are first called.  This is most noticeable when loading small datasets and mostly an issue if you run Julia in batch mode from the command line, as opposed to from within the REPL (except on the first run from within the REPL).  To avoid this overhead, one can use the PackageCompiler package.  To use it, do the following:","category":"page"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"add the PackageCompiler using ]add PackageCompiler in the REPL.\ncopy the contents of the extras folder on the github Grumps repository to your computer\nrun julia makesystemimage.jl\nthen, in the future, run julia -J *location of image.so* *other options*","category":"page"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"warning: New Julia versions\nThis procedure would have to be repeated every time you upgrade Julia to a new version\"","category":"page"},{"location":"misc/#Random-tips","page":"Miscellanea","title":"Random tips","text":"","category":"section"},{"location":"misc/","page":"Miscellanea","title":"Miscellanea","text":"In most programming languages, it is a bad idea to use global variables.  This is especially true in Julia.  So bury any variable definitions, etcetera, inside a function.  You may incur a significant performance hit if you don't.\nIf one used an estimated sigma_xi^2 in a two stage procedure, then the estimated sigma_xi^2 can be made arbitrarily small by adding many regressors to the delta on x regression.  This is a bad idea since it artificially puts all the weight on the product level moments.\nIf the splash screen bothers you, you can turn it off by writing const splashprobs = zeros( 4 ) before running using Grumps.","category":"page"},{"location":"acknowledgments/#Acknowledgments","page":"Acknowledgments","title":"Acknowledgments","text":"","category":"section"},{"location":"acknowledgments/","page":"Acknowledgments","title":"Acknowledgments","text":"I thank Paul Grieco, Charlie Murry, Stephan Sagl, Junpeng Hu, and Vivek Bhattacharya for helpful comments.","category":"page"},{"location":"speedmemory/#Speed,-memory,-and-accuracy","page":"Speed, memory, accuracy","title":"Speed, memory, and accuracy","text":"","category":"section"},{"location":"speedmemory/#Memory-conservation","page":"Speed, memory, accuracy","title":"Memory conservation","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"By default, Grumps loads all data and then creates space for all markets for things like choice probabilities, objective functions and their derivatives, intermediate objects, etcetera.  This saves computation time, but eats memory, especially as the number of random coefficients increases.","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"There are several ways of addressing memory issues.  First, it is generally a good idea to be modest in the number of random coefficients one uses.  In terms of computation it adds to memory demands.","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"Second, one can set memsave in OptimizationOptions() to true.  This reduces memory requirements by sharing space for choice probabilities and related objects across a number of markets based on the number of threads.  For instance, if there are ten markets and the number of market threads in OptimizationOptions() is set to two then the space for choice probabilities is shared across five markets.   The downside of doing this is that it slows down computation since some objects will need to be recomputed multiple times during estimation.   This is especially true for estimators that use the penalty term in the inside optimization, i.e. currently only the full Grumps estimator.  A secondary downside is that to implement this feature without excessive allocations, the code to achieve this is low-level.  In particular, do not call grumps! from different threads in the same program (different processes is fine) when using memsave. Note that memsave will have no effect if the number of market threads is no less than the number of markets. ","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"tip: When to use `memsave`\nTry turning memsave on if Grumps is paging or running out of RAM. Otherwise, leave it off. ","category":"page"},{"location":"speedmemory/#Speed","page":"Speed, memory, accuracy","title":"Speed","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"There are several reasons that would make Grumps slow:","category":"page"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"Grumps can naturally take a while if the data set is large.  \nWith quadrature, computation time grows fast in the number of random coefficients.  \nThe full CLER estimator (especially with memsave on) is slower than its cheap alternative.  \nUsing global variables is a bad idea in any programming language and especially in Julia (bury everything inside a function). In Julia type stability can also be an issue.\nTolerances and iteration counts (not an issue with the defaults).\nUsing robust choice probabilities makes run times longer (the default is fast). \nMake sure you are not running Julia in single thread mode.  Start Julia with julia -t 16 if you have 16 physical cores in your computer.\nThe number of threads used for various activities can be specified via OptimizationOptions().  The defaults may not be optimal, but are usually ok.\nUsing a BigFloat type instead of Float64 adds precision but the performance penalty is severe.","category":"page"},{"location":"speedmemory/#Accuracy","page":"Speed, memory, accuracy","title":"Accuracy","text":"","category":"section"},{"location":"speedmemory/","page":"Speed, memory, accuracy","title":"Speed, memory, accuracy","text":"The main things one can do to improve accuracy is to experiment with the tolerances.  Other options that would slow down computation are to use robust choice probabilities and higher precision floating points types, but that should be an option of last resort.","category":"page"},{"location":"aliens/#Interacting-with-other-languages","page":"Languages other than Julia","title":"Interacting with other languages","text":"","category":"section"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"There is only a version of Grumps for Julia.  However, you can call other languages from Julia using one of the PyCall, PythonCall, or RCall packages.  You can load Stata files via the StatFiles package.  To call C or Fortran code, see the Julia documentation.  For those using other software like Gauss and Matlab, consider writing results to disk and then reading them in the software you use.","category":"page"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"The code below provides an example in which the output is printed in Julia, Python, and R, respectively.","category":"page"},{"location":"aliens/","page":"Languages other than Julia","title":"Languages other than Julia","text":"using Grumps, PyCall, RCall\n\n\nfunction compute_stuff( meth  )\n\n    s = Sources(                                                            \n      consumers = \"example_consumers.csv\",\n      products = \"example_products.csv\",\n      marketsizes = \"example_marketsizes.csv\",\n      draws = \"example_draws.csv\"  \n    )\n    \n    v = Variables( \n        \"choice = income * constant + income * ibu + age * ibu + rc * ibu + rc * abv\",\n        \"share = constant + ibu + abv / constant, ibu, abv, IVgh_ibu, IVgh_abv\";\n        outsidegood = \"product 11\"                                \n    )\n    \n    e = Estimator( meth )                                                     \n    d = Data( e, s, v ) \n    return grumps!( e, d )           \nend\n\npy\"\"\"\ndef print_my_stuff_in_python(x):\n\tprint( \"Python: \", x )\n\n\"\"\"\n\nR\"\"\"\nprint_my_stuff_in_R <- function(x) cat( \"R: \", x, \"\\n\" ) \n\"\"\"\n\nfunction myprogram( )\n    sol = compute_stuff( :cheap )\n    θcoef =  getθcoef( sol )\n    println( \"Julia: $θcoef \\n\" )\n    py\"print_my_stuff_in_python\"(θcoef)\n    R\"print_my_stuff_in_R\"(θcoef)\nend\n\n\nmyprogram()","category":"page"},{"location":"bearinmind/#Things-to-bear-in-mind","page":"Things to bear in mind","title":"Things to bear in mind","text":"","category":"section"},{"location":"bearinmind/#Starting-values","page":"Things to bear in mind","title":"Starting values","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The global objective function is nearly convex in delta, so convergence of the inner optimization is generally uneventful.  Although the objective function is not convex in theta, the outer optimization usually achieves the optimum from a single starting value.  However, this is not guaranteed.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The most frequent case in which this would go wrong is when one or more of the theta^nu coefficients goes to zero and gets stuck.  This is more likely to happen when there are identification problems, e.g. when theta^z approx 0 and the product level moments do not provide much identifying power.  Just try a few other starting values.","category":"page"},{"location":"bearinmind/#Memory-consumption","page":"Things to bear in mind","title":"Memory consumption","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The program will become memory-hungry when the number of random coefficients is increased (assuming micro data are used).    Look at the memsave option to reduce memory consumption.","category":"page"},{"location":"bearinmind/#Zero-shares","page":"Things to bear in mind","title":"Zero shares","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) offers some robustness to shares that are equal to or very close to zero.  However, that requires that the product level moments are overidentified.","category":"page"},{"location":"bearinmind/#Efficiency","page":"Things to bear in mind","title":"Efficiency","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) is efficient if an optimal weight matrix for the product level moments (GMM) portion is used whenever there is overidentification in the product level moments.  This is usually accomplished in a two step procedure.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The default procedure in Grumps is a single step procedure with weight matrix (B^T B)^-1.  This produces estimates that are consistent with valid standard errors but that are not necessarily fully efficient.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"See DataOptions() on how to achieve full efficiency using a two step procedure.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"tip: Starting values of second stage\nOne can use the first stage estimates as starting values of the second stage.  Since the first stage estimates converge at the optimal rate, also, this second stage optimization should converge quickly.","category":"page"},{"location":"bearinmind/#Floating-point-numbers","page":"Things to bear in mind","title":"Floating point numbers","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"All numbers should be in the same floating point format.  The default (and only heavily tested) format is Float64, i.e. a 64-bit float.  But the code is designed to handle other formats.  This could be attractive if greater precision is desired.  So one could use some form of BigFloat, at the expense of increased memory use and a substantial increase in computation time.","category":"page"},{"location":"bearinmind/#Nesting-of-memsave","page":"Things to bear in mind","title":"Nesting of memsave","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"If the memsave option (see Optimization options and Memory conservation) is set to true then Grumps will use some low level code to avoid having to repeatedly allocate and free memory.  What this means is that it is a bad idea to have grumps! called from multiple threads simultaneously: from multiple processes should be fine.  If you do not know what this means then you should be ok. ","category":"page"},{"location":"objects/#User-Interface","page":"User interface","title":"User Interface","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The sections below describe the main calls needed to use Grumps.  For any functions that are not documented here, simply use ? in the REPL, e.g. ?Variables.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The way that Grumps works is that one first specifies where the data are stored, what specification to use, which estimator to use, etcetera, before calling the functions that actually perform work with these choices.  All sections below up to and including the choice of integration method specify things, data object creation and algorithm call create and compute things, and the remainder deals with the retrieval of estimation results and memory conservation.","category":"page"},{"location":"objects/#Data-entry","page":"User interface","title":"Data entry","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The methods below are used to enter data into Grumps.  With Sources() one specifies where the data can be found and with Variables() which variables to use from those data sources.  ","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Two versions of the Variables method\nThere are two versions of the Variables method, where the main difference is the syntax.  Use whichever one you prefer.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Sources()\nVariables()\nVariables( ::String, ::String, ::String, ::String )","category":"page"},{"location":"objects/#Grumps.Sources-Tuple{}","page":"User interface","title":"Grumps.Sources","text":"Sources( \n    T           = DefaultSourceTypes; \n    consumers   :: Any = nothing, \n    products    :: Any = nothing, \n    marketsizes :: Any = nothing, \n    draws       :: Any = nothing,\n    user        :: Any = nothing\n)\n\nCreates a GrumpsSources object with source type entries of type T where the entries are provided in the optional parameters.\n\nGrumps (potentially) uses four data sources: a data source for consumer-level data, one for product-level data, one for market size information, and one for demographic draws.  See Spreadsheet formats for data layouts. Only the product-level data are required, but are by themselves insufficient.  For instance, for BLP95 one needs information on products, market sizes, and demographics; for the Grumps CLER estimator one needs all four types of data; for a multinomial logit both consumer and product information are needed.  Not all data are needed for all markets.  For instance, it is ok for some estimators for there to be consumer-level data in some markets but not others.\n\nThe T argument is mostly there to allow for future expansion, so the description below applies to the case in which T = DefaultSourceTypes.\n\nBy default, the entries can be nothing, a string, a DataFrame, or a SourceFileType.  If an entry is nothing, it means that no such data is to be used.  If an entry is a string then it is converted to a SourceFileCSV entry with comma delimiter where the string name is the file name.  To use other source file types, create a SourceFileType first.  A DataFrame can be passed, also.  In all cases other than nothing, data will eventually be (converted to) a DataFrame and parsed from that.\n\nThe consumers variable specifies where consumer-level data can be found, the products variable is for the product-level data, marketsizes is for market sizes, and draws is for demographic draws; user has not been implemented yet.\n\nUse the Variables() method to specify the way the data sources are formatted and the specification to estimate.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Variables-Tuple{}","page":"User interface","title":"Grumps.Variables","text":"Variables( ; \n  market              :: Symbol = :market,\n  product             :: Symbol = :product,\n  choice              :: Symbol = :choice,\n  interactions        :: Mat{Symbol} = [],\n  randomcoefficients  :: Vec{Symbol} = [],\n  outsidegood         :: String = \"outsidegood\",\n  share               :: Symbol = :share,\n  marketsize          :: Symbol = :N,\n  regressors          :: Vec{Symbol} = [],\n  instruments         :: Vec{Symbol} = [],\n  dummies             :: Vec{Symbol} = [],\n  nuisancedummy       :: Symbol = :none,\n  microinstruments    :: Mat{Symbol} = [],\n  user                :: Mat{Symbol} = []\n    )\n\nThis method is used to specify regressors, instruments, random coefficients, interactions, variable labels, etcetera, from the sources you have specified in Sources(). It creates an object of type GrumpsVariables.\n\nFor instance, the option market specifies the column heading of the column containing the market descriptor (name).  The same is true for all other arguments, except outsidegood which describes the spreadsheet entry that indicates the product is an outside good.  The  same label for the outside good should be used in all spreadsheets and all markets. Outside good entries  should only be used in the consumer micro data and then only if there actually are consumers in the micro data choosing the outside good. All descriptors are case and space sensitive.\n\nThere is a separation between variables that go into the individual consumer utility and ones that only go into \"mean utility\".  For instance, interactions tells Grumps which interaction terms to use and randomcoefficients which product level regressors are hit with a random coefficient.  By contrast, regressors go into the mean utility component and are regressors in the \"second stage\" (where β is recovered). One can use the special symbol :constant to indicate a constant is to be used; the spreadsheet need not include a column with that heading.\n\nNote that there are three ways that dummy variables can be entered as second stage regressors, which can be useful to incorporate brand, firm, or market effects into δ.  The first is via regressors, in which case the onus is on the user to ensure that they have the correct numerical values.  The second possibility is via the dummies argument.  For  each symbol passed via the dummiesi pass one via the *nuisancedummy argument since it saves both computation time and memory.  There can only be at most one categorical variable that can be converted to nuisance dummies, but there can be arbitrarily many categories.  These dummies and nuisance dummies are automatically assumed to be exogenous and will be included in the instruments, also.\n\nmarket refers to the variable containing the market indicator in all input datasets.  Strings (e.g. \"Amarillo, Texas\") work best for the market indicators themselves, but it is not a requirement.\n\nproduct refers to the variable containing the product indicator in the product dataset. Strings (e.g. \"Camry\") work best for the product indicators themselves, but it is not a requirement.\n\nchoice refers to the variable indicating the choice indicator in the consumer level datasets.  Strings work best for the choice indicators themselves, but it is not a requirement.  These should take the values of the product column in the products data set or of the outsidegood.\n\ninteractions refers to the variables indicating consumer and product variable interactions (each row contains consumer variable, product variable)\n\nrandomcoefficients refers to the product level variables that have a random coefficient on them\n\noutsidegood refers to the label used for the outside good\n\nshare refers to the label used for the product level share; these are shares where the denominator includes the outside good\n\nmarketsize refers to the size of the market (number of people)\n\nregressors refers to the label used for the second stage regressors\n\ninstruments refers to the label used for the second stage instruments\n\ndummies refers to discrete variables to be converted to second stage dummy regressors and instruments\n\nnuisancedummy refers to at most one variable to be converted to a second stage dummy regressors and instrument whose coefficient value is of no interest\n\nmicroinstruments refers to micro instruments, which are only relevant for gmm style procedures\n\nuser refers to a list of variables to be added to the consumer-product interactions using a user-specified procedure.  This is only needed if the Grumps specification itself does not suffice: see Extending Grumps for details.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Variables-NTuple{4, String}","page":"User interface","title":"Grumps.Variables","text":"Variables( \n    microspec           :: String,\n    macrospec           :: String,\n    dummyspec           :: String = \"\",\n    nuisancedummyspec   :: String = \"\";\n    market              :: String = \"market\",\n    product             :: String = \"product\",\n    outsidegood         :: String = \"outsidegood\",\n    marketsize          :: String = \"N\",\n    microinstruments    :: String = \"\",\n    user                :: String = \"\"\n    )\n\nThis method is used to specify regressors, instruments, random coefficients, interactions, variable labels, etcetera, from the sources you have specified in Sources(). It creates an object of type GrumpsVariables.  There is another method by the same name that accomplishes much the same thing, but has a different user interface. \n\nThe method described here takes string arguments, including two mandatory ones, whereas the other method takes optional arguments only, mostly symbols, vectors of symbols, and matrices of symbols that can be passed in arbitrary order using keywords.  The current method parses user input before calling the other method.\n\nThe option market specifies the column heading of the column containing the market descriptor (name).  The same is true for all other  arguments, except outsidegood which describes the spreadsheet entry that indicates the product is an outside good.  The same label for  the outside good should be used in all spreadsheets and all markets. Outside good entries should only be used in the consumer micro data  and then only if there actually are consumers in the micro data choosing the outside good. All descriptors are case sensitive.\n\nThere is a separation between variables that go into the individual consumer utility and ones that only go into \"mean utility\".  For instance, to specify what goes into individual consumer utility, one could specify\n\n\"choice = loginc * msrp + famsize * logfootprint + famsize * van + urban * truck + rc * suv + rc * truck + rc * van\"\n\nas the microspec argument to indicate that consumer choice is in the micro data set in a column headed \"choice\" and that there are four interaction terms and three random coefficients.  The interaction terms have the consumer-level variable as the first factor and the product  variable as the second argument.  In this example the three random coefficients are on the suv, truck, and van variables and these variable names should correspond to the column headings in the product level data set.  One can use constant to indicate a constant is used: there is no need to include a constant in one's data.\n\nThe macrospec argument takes the form \n\n\"share = constant + logmpg + loghp + logfootprint + msrp | constant, logmpg, loghp, logfootprint, logcurbweight, lagplcon\"\n\nwhere share are product-level market shares, everything between = and | represents regressors, and everything after | represents  instruments; both regressors and instruments are for the product level moments portion.  One can again use constant to indicate a constant is used, which need not be included in one's data.\n\nFor the remaining arguments, see the description of the other method Variables().\n\n\n\n\n\n","category":"method"},{"location":"objects/#Optimization-options","page":"User interface","title":"Optimization options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default optimization options are sensible, in which case this section can be skipped.  But for those who want to play with tolerances and such, have at it.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"There is one exception, however, and that exception pertains to using less memory.  There is a separate section dedicated to that possibility, namely Memory conservation","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"OptimizationOptions()\nOptimOptionsθ()\nOptimOptionsδ()\nGrumpsThreads(; blas = 0, markets = 0, inner = 0 )","category":"page"},{"location":"objects/#Grumps.OptimizationOptions-Tuple{}","page":"User interface","title":"Grumps.OptimizationOptions","text":"OptimizationOptions(; \nθopt = OptimOptionsθ(), \nδopt = OptimOptionsδ(), \nthreads = GrumpsThreads(), \nmemsave = false, \nmaxrepeats = 4, \nprobtype = :fast,\nid = :Grumps\n)\n\nSets the options used for numerical optimization.  θopt is used for the external optimization routine, δopt for the internal one.  These are both of type OptimOptions; see the OptimOptionsθ and OptimOptionsδ methods for elaboration.  The memsave variable is set to false by default; turning it on will reduce memory consumption significantly, but will also slow down computation.  The variable maxrepeats may disappear in the  future.  \n\nThere are two ways of computing choice probabilities: robust and fast, specified by passing :robust or :fast in probtype. Fast choice probabilities are the default for good reason.\n\nFinally, specifying id allows one to add callbacks, e.g. user functions that are called on each inner and  outer iteration.  See the Extending Grumps portion of the documentation.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsθ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsθ","text":"OptimOptionsθ(; \nf_tol = 1.0e-8, \ng_tol = 1.0e-4, \nx_tol = 1.0e-5, \niterations = 25, \nshow_trace = true, \nstore_trace = true, \nextended_trace = true )\n\nCreates and returns an OptimOptions optimization options variable for the outer optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsδ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsδ","text":"OptimOptionsδ( ; \nf_tol = 1.0e-8, \ng_tol = 1.0e-8, \nx_tol = 1.0e-6, \niterations = 25, \nshow_trace = false, \nstore_trace = true, \nextended_trace = false )\n\nCreates and returns an OptimOptions optimization options variable for the inner optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.GrumpsThreads-Tuple{}","page":"User interface","title":"Grumps.GrumpsThreads","text":"GrumpsThreads(; \n    blas = 0, \n    markets = 0, \n    inner = 0 \n    )\n\nThis sets the number of threads to be used subject to a number of caveats.  blas refers to the number of BLAS threads, markets to the number of threads in loops over markets, and inner to the number of threads in inner loops.  A value of zero forces the automatic selection of the number of threads.\n\nOf these, inner is not currently used at all, market is only used in memsave mode, and blas is used.  However, please note that the number of threads used by Grumps altogether is the number of threads passed in via the command line argument (i.e. via the -t switch), where that number does not include the number of BLAS threads set.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Data-storage-options","page":"User interface","title":"Data storage options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default data storage options are sensible, but some space can be saved by tinkering with the settings.  The only parameter that is worth changing in the first version of DataOptions is σ2, which is the variance of ξ, the product level error term.  This is of no relevance for two-stage estimators like unpenalized mle.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The second version of DataOptions is more flexible.  The first argument allows the user to specify a variance matrix for ξ to be used in the construction of the product level moment component of the objective function.  This choice is irrelevant in an exactly identified system.  In an overidentified system it does not matter for consistency, asymptotic normality, conformance, or the convergence rate of the estimators provided that it is positive definite and fixed.  It can affect efficiency.  The second argument allows the user to specify how standard errors should be computed and also causes Grumps to compute an estimate of V xi that can be used as an input into a second stage.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"DataOptions()\nVarξInput{T}\nVarξHomoskedastic\nVarξHeteroskedastic\nVarξClustering\nVarξUser","category":"page"},{"location":"objects/#Grumps.DataOptions-Tuple{}","page":"User interface","title":"Grumps.DataOptions","text":"DataOptions(; \n    micromode   = :Hog\n    macromode   = :Ant\n    balance     = :micro\n    σ2          = 1.0\n    id          = :Grumps\n)\n\nBoth this method and the one described below specify how Grumps should store its data and what it should store.  This one is simpler but has less flexibility.  The first three options are best set to their defaults, unless you know what it is you're doing.  The σ2 option is the variance of ξ, i.e. the error variance in the product level moments.  The id option is used to extend Grumps with other data constructions.\n\nDataOptions(\n    VarξInput   :: VarξInput{T},\n    VarξOutput  :: VarξOutput = VarξDefaultOutput,\n    micromode   :: Symbol = :Hog,\n    macromode   :: Symbol = :Ant,\n    balance     :: Symbol = :micro,\n    id          :: Symbol = :Grumps   \n)\n\nBoth this method and the one described above specify how Grumps should store its data and what it should store.  This one is both more complex and more flexible.  The micromode, macromode, and balance arguments are best kept at their defaults, unless you know what it is you're doing.  The id option is used to extend Grumps with other data constructions.  VarξInput is the variance matrix to be used in the penalty term weight matrix construction.  This should be a J by J matrix where J is the number of products across all markets.  Acceptable types for VarξInput include UniformScaling{T} (e.g. 1.0 * I ) and AbstractMatrix{T} (sparse matrix is recommended to conserve space, but a dense matrix is allowed).  VarξOutput is used to indicate what assumptions on the variance of ξ must be produced in the solution, which can subsequently be used as an input in a second stage if desirable; options are VarξHomoskedastic, VarξHeteroskedastic, VarξClustering, and VarξUser.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.VarξInput","page":"User interface","title":"Grumps.VarξInput","text":"const VarξInput{T} = Union{ UniformScaling{T}, AbstractArray{T} }\n\nType used to characterize the assumption under which the weight matrix for the product level moments component of the objective function should be computed.  This is irrelevant for consistency, conformance, or the convergence rate of the estimator but it can affect asymptotic efficiency.\n\n\n\n\n\n","category":"type"},{"location":"objects/#Grumps.VarξHomoskedastic","page":"User interface","title":"Grumps.VarξHomoskedastic","text":"VarξHomoskedastic()\n\nCreates a variable of type VarξHomoskedastic.  This is used to indicate that standard errors should be computed under the assumption of homoskedasticity.  This choice does not affect efficiency.  It also products an estimate of the matrix V(ξ) as part of the solution object, which can be used as an input into a possible second stage.\n\n\n\n\n\n","category":"type"},{"location":"objects/#Grumps.VarξHeteroskedastic","page":"User interface","title":"Grumps.VarξHeteroskedastic","text":"VarξHeteroskedastic()\n\nCreates a variable of type VarξHeteroskedastic.  This is used to indicate that standard errors should be computed under the assumption of heteroskedasticity.  This choice does not affect efficiency.  It also products an estimate of the matrix V(ξ) as part of the solution object, which can be used as an input into a possible second stage.\n\n\n\n\n\n","category":"type"},{"location":"objects/#Grumps.VarξClustering","page":"User interface","title":"Grumps.VarξClustering","text":"VarξClustering( clusteron :: Symbol )\n\nCreates a variable of type VarξClustering.  This is used to indicate that standard errors should be computed under the assumption of clustering.  This choice does not affect efficiency.  It also products an estimate of the matrix V(ξ) as part of the solution object, which can be used as an input into a possible second stage.  The argument is the variable one should cluster on, e.g. VarξClustering( :market ) suggests that Grumps should cluster on the variable contained in the column in the products spreadsheet with column heading market.\n\n\n\n\n\n","category":"type"},{"location":"objects/#Grumps.VarξUser","page":"User interface","title":"Grumps.VarξUser","text":"VarξUser()\n\nAllows the user to specify its own standard error computation procedure.  Look at Grumps.Template to see how this is implemented.\n\n\n\n\n\n","category":"type"},{"location":"objects/#Standard-error-options","page":"User interface","title":"Standard error options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"By default, Grumps computes standard errors for all coefficients.  This option allows one to change that.  For instance, standard errors may not be needed for all elements of delta.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"StandardErrorOptions()","category":"page"},{"location":"objects/#Grumps.StandardErrorOptions-Tuple{}","page":"User interface","title":"Grumps.StandardErrorOptions","text":"StandardErrorOptions(; θ = true, δ = true, β = true )\n\nSpecifies which coefficients to create standard errors for.  If you are looking for what type of standard errors to produce, look at DataOptions().\n\n\n\n\n\n","category":"method"},{"location":"objects/#Estimator-choice","page":"User interface","title":"Estimator choice","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps can compute quite a few estimators and one can specify which estimator to use by passing the return value of a call to Estimator to the optimization routine.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The easiest way to call Estimator is by passing it a string that describes what it is that you want to do.  For a description of these estimators, see Estimators.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Estimator( s :: String )\nEstimator( s :: Symbol )\nEstimators()","category":"page"},{"location":"objects/#Grumps.Estimator-Tuple{String}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: String )\n\nCreates and returns a GrumpsEstimator type.  Grumps is reasonably good at figuring out what it is that you want, so e.g. Estimator( \"maximum likelihood\" ) gives you the unpenalized Grumps maximum likelihood estimator.\n\nThe estimators currently programmed include:\n\nthe full CLER estimator\na cheaper alternative to CLER that has the same limit distribution\nMDLE, i.e CLER without product level moments\nmixed logit with share constraints\nmixed logit estimator using micro data only\nGMM estimators of the same model (in progress: not recommended)\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimator-Tuple{Symbol}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: Symbol )\n\nCreates and returns a GrumpsEstimator type.\n\nThis is one method of specifying the estimator used.  However, it is unforgiving in that the exact symbol used internally must be passed, so the Estimator( s :: String ) method is usually a better choice.\n\nPossible choices include:\n\n:cler the full CLER estimator  \n\n:cheap a cheaper alternative to CLER that has the same limit distribution\n\n:mdle MDLE, i.e CLER without product level moments\n\n:shareconstraint mixed logit with share constraints\n\n:mixedlogit mixed logit estimator using micro data only\n\n:gmm  GMM estimator of the same model (in progress: not recommended)\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimators-Tuple{}","page":"User interface","title":"Grumps.Estimators","text":"Estimators( elaborate = false )\n\nPrints a list of available estimators.  The argument indicates whether a lot of features should be printed  or few.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Choice-of-integration-method-(integrators)","page":"User interface","title":"Choice of integration method (integrators)","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps uses separate integration methods for the micro and macro components. This section will discuss the default choices, which are the only integrators implemented as part of the package.  Users may implement their own integration routines, see adding an integrator.   ","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"For integrating the micro likelihood (over nu), the default method is Hermitian quadrature which assumes nu is standard normally distributed. Users may select the number of nodes per dimension. ","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"For integrating the macro likelihood (over nu and z), the default method is Monte Carlo integration. In this default, nu is assumed to be standard normally distributed.  The distribution of z can either be (1) assumed to be standard normally distributed or (2) simulated using draws from its distribution provided by the user. Option (2) should be used in applications where a sample of z is available (e.g., consumer survey); the sample should be specified as the draws spreadsheet described in Spreadsheet formats. ","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Default Integration\nOne gets defaults if the integrator arguments are omitted in the call to Data().  The default integrators use a small number of nodes / draws in the sense that they emphasize speed / storage over accuracy, unless specified otherwise as documented below.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"DefaultMicroIntegrator( ::Int, ::Type )\nDefaultMicroIntegrator( ::Type )\nDefaultMacroIntegrator( ::Int, ::Type )\nDefaultMacroIntegrator( ::Type )","category":"page"},{"location":"objects/#Grumps.DefaultMicroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMicroIntegrator","text":"DefaultMicroIntegrator( n :: Int, T :: Type = Float64; options = nothing )\n\nCreates a basic quadrature Integrator using n nodes in each dimension.  Type T can be omitted, in which case it is Float64. The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMicroIntegrator-Tuple{Type}","page":"User interface","title":"Grumps.DefaultMicroIntegrator","text":"DefaultMicroIntegrator( T :: Type; options = nothing )\n\nCreates a basic quadrature Integrator using 11 nodes in each dimension.   Type T can be omitted, in which case it is Float64.  The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMacroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMacroIntegrator","text":"DefaultMacroIntegrator( n :: Int, T :: Type; options :: Union{Vec{Symbol}, Nothing} = nothing )\n\nCreates a basic Monte Carlo Integrator using n draws.  Type T can be omitted, in which case it is Float64. The optional options argument can be used to indicate two possible changes from the default, namely :randomize can be used to require randomization and :replacement to indicate randomization with  replacement. The default for both is false. Note that options is either nothing or a vector of symbols.   A further use of options is to specify a column heading containing weight; this symbol should correspond to the desired column heading in the draws spreadsheet. \n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMacroIntegrator-Tuple{Type}","page":"User interface","title":"Grumps.DefaultMacroIntegrator","text":"DefaultMacroIntegrator( T )\n\nCreates a basic Monte Carlo Integrator using 10 000 draws.  This is less than recommended, so use the other method to set a number of your choosing.  Type T can be omitted, in which case it is Float64. The optional options argument can be used to indicate two possible changes from the default, namely :randomize can be used to require randomization and :replacement to indicate randomization with  replacement.  Note that options is either nothing or a vector of symbols.  The defaults for both is false. A further use of options is to specify a column heading containing weight; this symbol should correspond to the desired column heading in the draws spreadsheet. \n\n\n\n\n\n","category":"method"},{"location":"objects/","page":"User interface","title":"User interface","text":"warning: Default macro integrator options and draws\nUnless specified otherwise, the default macro integrator uses Monte Carlo integration with R = 10000 draws unless otherwise specified.  If one does not specify randomization then the default macro integrator simply uses the first R lines of draws for each market for demographics (z draws) and combines them with R draws from the distribution of the random coefficients (nu draws), both of which are then interacted with the product level regressors (x variables).  If the spreadsheet does not contain enough rows corresponding to a market then the program will cycle and throw a warning.  With randomization with replacement, R numbers are drawn from the draws spreadsheet regardless of the number of lines in the spreadsheet.  Without replacement, the same occurs and if the spreadsheet does not contain enough lines corresponding to the market, all lines are added and then the procedure is repeated.  In other words, there is replacement by necessity.  Again, a warning will be displayed. With randomization, the random numbers are drawn separately for each market.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The remaining integration methods are only germane for GMM, which is in progress.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"MSMMicroIntegrator( :: Int, ::Type )\nMSMMicroIntegrator( ::Type )","category":"page"},{"location":"objects/#Grumps.MSMMicroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.MSMMicroIntegrator","text":"MSMMicroIntegrator( n :: Int, T = F64; options = nothing )\n\nCreates a Monte Carlo integrator type for micro integration with GMM with smart moments.  The optional type can be omitted. The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.MSMMicroIntegrator-Tuple{Type}","page":"User interface","title":"Grumps.MSMMicroIntegrator","text":"MSMMicroIntegrator( T = F64; options = nothing )\n\nCreates a Monte Carlo integrator type for micro integration with GMM with smart moments with 10 MC draws (per consumer). The type variable is optional and can be omitted.  The options variable is ignored.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Data-object-creation","page":"User interface","title":"Data object creation","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The data stored in spreadsheets or other objects have to be converted into a form that Grumps understands.  The call to Data achieves that.   It takes as inputs the various choices made by the user and then creates an appropriate data object that is subsequently passed to the optimization call.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Data()","category":"page"},{"location":"objects/#Grumps.Data-Tuple{}","page":"User interface","title":"Grumps.Data","text":"Data( \n    e                   :: GrumpsEstimator,\n    ss                  :: Sources,\n    v                   :: Variables,\n    microintegrator     :: MicroIntegrator = DefaultMicroIntegrator(),\n    microintegrator     :: MacroIntegrator = DefaultMacroIntegrator(),\n    T                   :: Type = F64,\n    options             :: DataOptions = GrumpsDataOptions(),\n    replicable          :: Bool = false\n    )\n\nTakes user inputs and converts them into an object that Grumps can understand.  This is synonymous with GrumpsData(...).\n\nData takes the following arguments, of which the first three are mandatory:\n\ne:                   estimator; see Estimator choice\nss:                  data sources; see Data entry\nv:                   variables to be used; see Data entry\no:                   optimization options to be used   \nmicrointegrator:     micro integrator see Choice of integration method (integrators)\nmacrointegrator:     macro integrator see Choice of integration method (integrators)\nT:                   floating point type; not heavily tested\nu:                   not yet implemented\noptions:             data options to be used, see Data storage options\nreplicable:          whether results must be replicable (slows down speed of data creation if set to true)\n\n\n\n\n\n","category":"method"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Ensuring replicability\nIf you need replicability, set replicable=true.  This means that you will get exactly the same results if you run the program multiple times on the same machine with the same Grumps version and the same packages loaded.  The downside of enforcing replicability is that it slows down data object generation since the data objects are then not generated in parallel.  Optimization itself will still be done in parallel however.","category":"page"},{"location":"objects/#Algorithm-call","page":"User interface","title":"Algorithm call","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Once all data structures have been put together, one can call the algorithm.  This is straightforward.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"    grumps!( ::Estimator, ::Data{T}, ::OptimizationOptions, ::Grumps.StartingVector{T}, ::StandardErrorOptions ) where {T<:Grumps.AbstractFloat}","category":"page"},{"location":"objects/#Grumps.grumps!-Union{Tuple{T}, Tuple{Estimator, Data{T}, OptimizationOptions, Union{Nothing, Vector{T}}, StandardErrorOptions}} where T<:AbstractFloat","page":"User interface","title":"Grumps.grumps!","text":"grumps!( \n    e       :: Estimator,\n    d       :: Data{T},\n    o       :: OptimizationOptions = OptimizationOptions(),\n    θstart  :: StartingVector{T} = nothing,\n    seo     :: StandardErrorOptions = StandardErrorOptions()\n)\n\nConducts the optimization.  You typically just want to set θstart to nothing, i.e. have a starting vector  picked automatically.  \n\n\n\n\n\n","category":"method"},{"location":"objects/#Retrieving-results","page":"User interface","title":"Retrieving results","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"As noted above, Grumps will return its results in a variable of type GrumpsSolution that can be queried or saved as follows.  You can also simply call one of the print or  related functions on any of these objects.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Finally, you can call any of minimum, iterations, iteration_limit_reached, converged, f_converged, g_converged, x_converged, f_calls, g_calls, h_calls, f_trace, g_norm_trace, x_trace on a GrumpsSolution object in the same way that you would query the return value in the Optim package, albeit that they are not in the namespace by default. E.g., if sol is a GrumpsSolution object,  use Grumps.converged(sol) instead of converged(sol).","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"getθ( sol :: GrumpsSolution )\ngetδ( sol :: GrumpsSolution )\ngetβ( sol :: GrumpsSolution )\ngetcoef( e :: GrumpsEstimate )\ngetstde( e :: GrumpsEstimate )\ngettstat( e :: GrumpsEstimate )\ngetname( e :: GrumpsEstimate )\ngetθcoef( sol :: GrumpsSolution )\ngetδcoef( sol :: GrumpsSolution )\ngetβcoef( sol :: GrumpsSolution )\nSave( fn :: AbstractString, mt :: MimeText, x :: Any; kwargs... )\nSave( fn :: AbstractString, x :: Any; kwargs... )\nshow( io :: IO, e :: GrumpsEstimate{T}, s :: String = \"\"; adorned = true, printstde = true, printtstat = true ) where {T<:AbstractFloat}\nshow( io :: IO, est :: Vector{ GrumpsEstimate{T} }, s :: String = \"\"; adorned = true, header = false, printstde = true, printtstat = trVariables()ue ) where {T<:AbstractFloat}\nshow( io :: IO, convergence :: Grumps.GrumpsConvergence{T}; header = false, adorned = true ) where {T<:AbstractFloat}\nshow( io :: IO, sol :: GrumpsSolution{T}; adorned = true, printθ = true, printβ = true, printδ = false, printconvergence = true ) where {T<:AbstractFloat}\nshow( io :: IO, mt :: MimeTex, sol :: GrumpsSolution; kwargs... ) \nshow( io :: IO, mt :: MimeCSV, sol :: GrumpsSolution; kwargs... ) ","category":"page"},{"location":"objects/#Grumps.getθ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getθ","text":"getθ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for θ that can be queried for results.  See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getδ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getδ","text":"getδ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for δ that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getβ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getβ","text":"getβ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for β that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getcoef-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getcoef","text":"getcoef( e :: GrumpsEstimate )\n\nReturns the estimated coefficient value.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getstde-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getstde","text":"getstde( e :: GrumpsEstimate )\n\nReturns the standard error.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.gettstat-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.gettstat","text":"gettstat( e :: GrumpsEstimate )\n\nReturns the t statistic.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getname-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getname","text":"getname( e :: GrumpsEstimate )\n\nReturns the variable name.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getθcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getθcoef","text":"getθcoef( sol :: GrumpsSolution )\n\nReturns a vector of θ coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getδcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getδcoef","text":"getδcoef( sol :: GrumpsSolution )\n\nReturns a vector of δ coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getβcoef-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getβcoef","text":"getβcoef( sol :: GrumpsSolution )\n\nReturns a vector of β coefficients\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Save-Tuple{AbstractString, Union{MIME{Symbol(\"text/tex\")}, MIME{Symbol(\"text/csv\")}, MIME{Symbol(\"text/plain\")}}, Any}","page":"User interface","title":"Grumps.Save","text":"Save( fn, mt, sol :: GrumpsSolution; keywords... )\n\nSaves the solution stored in sol to a file with filename fn which has mime type mt.  \n\nThere are several keywords that are described below, some of which will be ignored for some mime types.  Allowed mime types are text/plain, text/csv, and text/tex.\n\nKeyword Description Default\ncolsep column separator \",\"\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Save-Tuple{AbstractString, Any}","page":"User interface","title":"Grumps.Save","text":"Save( fn, sol :: GrumpsSolution; keywords... )\n\nThe same as the form of Save with prespecified mime type except that the mime type is now inferred from the file extension.  The keywords also have the same meaning, namely...\n\nThere are several keywords that are described below, some of which will be ignored for some mime types.  Allowed mime types are text/plain, text/csv, and text/tex.\n\nKeyword Description Default\ncolsep column separator \",\"\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsEstimate{T}}, Tuple{IO, GrumpsEstimate{T}, String}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, e :: GrumpsEstimate{T}, s :: String = \"\"; keywords...)\n\nShow a GrumpsEstimate object on io; the argument s indicates which parameter family (θ,β,δ) the estimate belongs to.  The optional keywords are described in the table below.\n\nKeyword Description Default\nadorned make output pretty? true\nprintstde print standard errors? true\nprinttstat print t statistics? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, Array{GrumpsEstimate{T}, 1}}, Tuple{IO, Array{GrumpsEstimate{T}, 1}, String}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, est :: Vector{ GrumpsEstimate{T} }, s :: String = \"\"; keywords... )\n\nShows a vector of estimates on io using the string s (typically one of θ,β,δ).  The command takes the following optional keywords.\n\nKeyword Description Default\nadorned make output pretty? true\nprintstde print standard errors? true\nprinttstat print t statistics? true\nheader descriptive header? false\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsConvergence{T}}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, convergence :: GrumpsConvergence{T}; keywords...)\n\nShows the contents of convergence, where the flags indicated what should be printed and how, as indicated in the following table.\n\nKeyword Description Default\nadorned make output pretty? true\nheader descriptive header? false\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Union{Tuple{T}, Tuple{IO, GrumpsSolution{T}}} where T<:AbstractFloat","page":"User interface","title":"Base.show","text":"show( io :: IO, sol :: GrumpsSolution{T}; keywords... )\n\nShows the contents of sol, where the keywords indicate what should be printed and how, as described in the table below.\n\nKeyword Description Default\nadorned make output pretty? true\nprintθ print θ results? true\nprintβ print β results? true\nprintδ print δ results? false\nprintconvergence convergence stats? true\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Tuple{IO, MIME{Symbol(\"text/tex\")}, GrumpsSolution}","page":"User interface","title":"Base.show","text":"show( io :: IO, mt :: MIME{Symbol(\"text/tex\")}, sol :: GrumpsSolution; keywords... )\n\nThis is the same as Save() except that the contents are spit out on io (which could be stdout or an already opened file).\n\n\n\n\n\n","category":"method"},{"location":"objects/#Base.show-Tuple{IO, MIME{Symbol(\"text/csv\")}, GrumpsSolution}","page":"User interface","title":"Base.show","text":"show( io :: IO, mt :: MIME{Symbol(\"text/csv\")}, sol :: GrumpsSolution; keywords... )\n\nThis is the same as Save() except that the contents are spit out on io (which could be stdout or an already opened file).\n\n\n\n\n\n","category":"method"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Saving results to LaTeX\nTo save estimation results directly to a LaTeX tabular, just use a .tex extension in the filename.  For instance, write Save( \"results.tex\", sol ) if your solution is in the variable sol.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"tip: Saving output printed to terminal\nTo save the terminal output to html, one can use Aha, the Ansi HTML Adapter, which is a small program (unrelated to Julia) that converts terminal output to html.  The way that would work on Linux and Mac (after successful installation) if one ran Grumps directly from the command line is to append | aha > myrun.html, e.g. julia -t auto myprogram.jl | aha > myrun.html.","category":"page"},{"location":"extending/#Extending-Grumps","page":"Extending Grumps","title":"Extending Grumps","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Grumps can be extended in multiple ways.  Below three possibilities are discussed, namely using an existing estimator for a different data format, introducing a new estimator, and introducing a new integrator.","category":"page"},{"location":"extending/#examining-output-at-each-iteration","page":"Extending Grumps","title":"examining output at each iteration","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"On each iteration of both the inner and outer optimization steps, Grumps calls a callback function.  By default the callback for the inner optimization does nothing and the callback for the outer optimization prints a summary of progress.  Users can add to this by defining their own callback functions named δcallback and θcallback respectively.  These are called before Grumps continues with its own callback routine.  ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"To do this, one has to pass an id to OptimizationOptions() and define a callback that is specifically for this id.  The id should be a symbol, i.e. a word preceded by a colon.  For instance, one can specify id = :myid and define the callback","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function Grumps.θcallback( ::Val{ :myid }, statevec, e, d, o, oldx, repeatx, solution ) \n\n        println( \"hi\" )\n        \n    end","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Then include o = OptimizationOptions(; id = :myid ) (possibly with other options) in the program and pass o as an argument to grumps!.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This will print \"hi\" on every θ iteration.  The first argument of Grumps.θcallback specifies which id this callback refers to (in case there is more than one), statevec is the state vector of the Optim package (see the documentation of that package for details), oldx is the θ-vector value of the previous iteration, and repeatx is a single element vector that indicates how often the same value of the parameter vector has been repeated.  Messing with the values of the arguments is not recommended.  The Grumps.δcallback function has the same syntax but lacks the solution argument.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"If the id variable is set but no user callbacks are defined then Grumps will only execute the default callbacks.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"note: Do not overuse Grumps.δcallback\nIf one has many markets then the δ callback is called a lot. Be prepared for a lot of output.  The θ callback is not called nearly as often.","category":"page"},{"location":"extending/#using-a-new-data-format","page":"Extending Grumps","title":"using a new data format","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The format of Grumps is limited to specifications that are linear in parameters.  This cannot be altered.  The way that data are entered moreover presumes that there are only interactions of demographics and product level variables, interactions of random coefficients and product level variables, product level regressors (where product level regressors can include a constant), a quality variable xi, and an error term epsilon.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This can be changed, however.  Pretty much all methods that Grumps uses to create data take an input parameter named id.  This corresponds to the id set in DataOptions(), which is :Grumps by default.  This id can be set to any other symbol.  For instance, if one set id to :myid then one could add any of the methods taking an id in any of the Julia code files in src/common/data with one's own version.  For instance, the following method is defined in micro.jl:","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function CreateInteractions( id ::Any, dfc:: AbstractDataFrame, dfp:: AbstractDataFrame, v :: Variables, T = F64 )\n        MustBeInDF( v.interactions[:,1], dfc, \"consumer data frame\" )\n        MustBeInDF( v.interactions[:,2], dfp, \"product data frame\" )\n\n        S = nrow( dfc )\n        J = nrow( dfp ) + 1\n        dθz = size( v.interactions, 1 )\n        Z = zeros( T, S, J, dθz )\n        for t ∈ 1:dθz, j ∈ 1:J-1, i ∈ 1:S\n            Z[i,j,t] = dfc[i, v.interactions[t,1] ] * dfp[j, v.interactions[t,2] ]\n        end\n        return Z\n    end","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"If one now defines a new method in one's own code with ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    function Grumps.CreateInteractions( ::Val{ :myid }, dfc, dfp, v, T )\n        ...\n        ...\n        ...\n    return Z\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"then Grumps will call the newly minted method instead of the default one.  But note that one would also need to adjust the corresponding macro integration part for estimators that use both micro and macro likelihoods.  For any functions for which no user-defined methods corresponding to the given id are defined, the default method is called.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"note: hogs and ants\nBy default, Grumps saves on storage by storing macro draws and regressors separately (:Ant mode for macro).  If one wanted a regressor that could not be expressed as e.g. the product of a demographic variable and a product variable, then the functions FillAθ! and FillZXθ! in src/common/probs/index.jl may need to have new methods added, also, if one wants to continue using :Ant mode.  An alternative for small problems is to switch to :Hog mode for the macro likelihood (the micro likelihood uses :Hog mode by default).","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"warning: two ids\nThere is one id for data creation passed in DataOptions() and one id for the optimization process passed in OptimizationOptions().  These ids can be different, but in most instances it is better to set these to the same value.  Note that the id used in FillAθ! and FillZXθ! is the optimization process id, not the data storage id.","category":"page"},{"location":"extending/#adding-a-new-estimator","page":"Extending Grumps","title":"adding a new estimator","text":"","category":"section"},{"location":"extending/#estimator-definitions","page":"Extending Grumps","title":"estimator definitions","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"A new estimator can be added by creating a new folder in the estimators folder.  By creating the folder, Grumps will automatically try to load an eponymous Julia file in that folder every time Grumps is run.  For instance, in src/estimators/cler you see a file cler.jl, which loads all Julia files in the folder other than description.jl. The file description.jl is loaded separately and automatically. ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The symbol used for the new estimator will correspond to the folder name.  For instance, if the folder name is foo then the new estimator symbol will be :foo.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The file description.jl should contain exactly two functions: name and Description.  It suffices to copy the description.jl file from another estimators folder and changing the particulars for your estimator.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For instance, the cler folder contains the file description.jl with contents","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"name( ::Val{:cler} ) = \"Conformant Likelihood with Exogeneity Restrictions\"\n\n\nfunction Description( e :: Symbol, v ::Val{ :cler } )\n    @ensure e == :cler \"oops!\"\n    return EstimatorDescription( e, name( Val( :cler ) ), \n      [ \"grumps\", \"pmle\", \"grumps penalized mle\", \"penalized likelihood\", \"grumps penalized maximum likelihood\", \"pml\", \"penmaxlik\", \"grumps pml\", \"cler\", \"full cler\" ]\n      )\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"All you need to do here is to change all the :cler entries to :foo, to change the return value of name to \"Foo Estimator\" and the array of strings in the return value of Description to a list of descriptors of your estimation method that define it clearly and set it apart from other estimators.  Make sure that none of the descriptors are used by other estimators.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"In a file loaded by foo.jl, preferably types.jl, one should define some properties of the estimators. In addition, there is a type associated with your estimator. For instance, the file types.jl in the cler folder contains","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"struct GrumpsCLEREstimator <: GrumpsPenalized\n    function GrumpsCLEREstimator() \n        new()\n    end\nend\n\nname( ::GrumpsCLEREstimator ) = name( Val( :cler ) )\n\ninisout( ::GrumpsCLEREstimator ) = true\n\nEstimator( ::Val{ :cler } ) = GrumpsCLEREstimator()","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The estimator type GrumpsCLEREstimator is used to allow Grumps to use the same function name with the estimator type to call different methods.  Note that GrumpsCLEREstimator is a subtype of GrumpsPenalized, which is done to allow for a single function call with different estimator type argument to select a method for all estimators that are subtypes of GrumpsPenalized.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For example, if one calls a function with an estimator type (and other arguments) then there is a default method that will be called unless there is a method defined for the desired supertype (e.g. GrumpsPenalized), which will be called unless there is a method defined for the exact estimator type (e.g. GrumpsCLEREstimator).","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For instance, the outer objective functions are all called ObjectiveFunctionθ! but which one is used depends on the estimator supertype.  For GrumpsPenalized it is the one in src/common/optim/objpml.jl.  Note that you can define different objective functions depending on e.g. the GrumpsData type that is passed, also.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For the new estimator :foo the name and Estimator methods in the above file can be changed by replacing :cler with :foo and CLER with Foo everywhere, assuming that the new estimator type is GrumpsFooEstimator.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The final entry in types.jl is the line  inisout( ::GrumpsCLEREstimator ) = true What this line does is to tell Grumps that the value of the likelihood component of the objective function in the inner optimization problem is the same as that in the outer optimization problem.  This is true for most estimators, but not for e.g. the share constraint estimator.  There are a number of properties like this (type Estimators(true) in the REPL to see them all), whose default values are in src/common/types/est.jl.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Now, the :mdle (the Grumps estimator with exact identification in the product level moments) and :shareconstraint (ditto, but where the inner optimization runs maximizes only the macro likelihood) computations differ only in the contents of the theta.jl and delta.jl files.  In this case, the theta.jl files produce the single market outer objective function contributions and its first two derivatives and delta.j does ditto for the inner objective functions.","category":"page"},{"location":"extending/#Data-types","page":"Extending Grumps","title":"Data types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"There are several predefined Data types, which can be found in src/common/types/data.jl.  For instance, GrumpsData contains a vector of GrumpsMarketData objects (one for each market), a GrumpsPLMData object, and some other things.  GrumpsPLMData is for the penalty term.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Each GrumpsMarketData object contains a GrumpsMicroData object and a GrumpsMacroData object, one for the micro portion of the likelihood, and one for the macro portion of the likelihood.  These are themselves supertypes, so you can use/require whichever subtype you desire for your estimator, but if one of the existing ones suffices then use that.","category":"page"},{"location":"extending/#FGH-types","page":"Extending Grumps","title":"FGH types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"FGH types contain the objective function and its derivatives.  These can be by market or apply to (or contain results for) a number of markets.  If inisout returns true then the inner and outer objective FGH objects are physically the same.","category":"page"},{"location":"extending/#Space-types","page":"Extending Grumps","title":"Space types","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Grumps preallocates space for choice probabilities and related objects and reuses their values where possible.  This saves computation time.  In most instances, the space types provided will suffice.","category":"page"},{"location":"extending/#adding-an-integrator","page":"Extending Grumps","title":"adding an integrator","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The default integrators used by Grumps (see DefaultMicroIntegrator( ::Int, ::Type ) and DefaultMacroIntegrator( ::Int, ::Type )) are limited in their functionality.  It is possible to define a new integrator. ","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"warning: Adding integrators is untested\nProceed with caution, ask for help if stuck.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The way to accomplish this is to create a new folder in src/integrators and create a Julia file with the same name in that folder.  For instance, the folder could be called myintegrator and the file in that folder myintegrator.jl.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"There are two types of integrators.  The example below will be for a micro integrator: the procedure for adding a macro integrator is similar.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"Consider the definition of the DefaultMicroIntegrator in src/common/types/nodesweights.jl:","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"    struct DefaultMicroIntegrator{T<:Flt} <: MicroIntegrator{T}   \n        n   :: Int\n    end","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This defines a MicroIntegrator called DefaultMicroIntegrator that uses a single integer-valued parameter n and can handle arbitrary floating point numbers (Flt is shorthand for AbstractFloat).  We need to define a constructor for that, which is defined in the same file, namely:","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"function DefaultMicroIntegrator( n :: Int, T = F64; options = nothing )\n    @ensure n > 0  \"n must be positive\"\n    DefaultMicroIntegrator{T}( n )\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"This is how one creates a variable of type DefaultMicroIntegrator.  This constructor requires n to be specified, takes Float64 as the default floating point type, and does not use any further options.  The options argument is there in case one wants to define additional inputs to the integrator.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For every integrator, one should define two methods: NodesWeightsGlobal and NodesWeightsOneMarket.  For the DefaultMicroIntegrator the method NodesWeightsGlobal is lengthy and its contents below are omitted.  Its NodesWeightsOneMarket method is very short and it is displayed in its entirety.  The full method definitions can be found in src/common/integration/micro.jl.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"function NodesWeightsGlobal( ms :: DefaultMicroIntegrator{T}, d :: Int,  rng :: AbstractRNG ) where {T<:Flt}\n    ( lengthy content omitted )\n  return GrumpsNodesWeights{T}(n, w)\nend\n\nfunction NodesWeightsOneMarket( ms :: DefaultMicroIntegrator{T}, d :: Int, rng :: AbstractRNG, nwgmic :: GrumpsNodesWeights{T}, S :: Int ) where {T<:Flt}\n   return nwgmic\nend","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"The reason that there is both a global method and a method for a single market is that for some integrators (like DefaultMicroIntegrator) the nodes and weights are the same for each market so only have to be generated once in NodesWeightsGlobal and can then simply be reused for every market.  This is why NodesWeightsOneMarket for DefaultMicroIntegrator simply returns its nwgmic argument: those are simply the nodes and weights generated in NodesWeightsGlobal.","category":"page"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"For the DefaultMacroIntegrator the converse is true: NodesWeightsGlobal does nothing and NodesWeightsOneMarket does all the work.  These methods can be found in src/common/integration/macro.jl, where it should be noted that the prototypes for macro integrators differ from those for micro integrators.","category":"page"},{"location":"quickstart/#Quick-Start-Guide","page":"Quick start","title":"Quick Start Guide","text":"","category":"section"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To use Grumps.jl consider the following program, which computes the penalized maximum likelihood estimator of Grieco, Murry, Pinkse, and Sagl.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"using Grumps\n\n\n\nfunction myprogram(  )\n\n    @info \"setting source files\"\n    s = Sources(\n        consumers = \"example_consumers.csv\",\n        products = \"example_products.csv\",\n        marketsizes = \"example_marketsizes.csv\",\n        draws = \"example_draws.csv\"  \n    )\n    println( s )\n\n     v = Variables(\n        interactions =  [\n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        randomcoefficients =  [:ibu; :abv],\n        regressors =  [ :constant; :ibu; :abv ],\n        instruments = [ :constant; :ibu; :abv; :IVgh_ibu; :IVgh_abv ],\n        outsidegood = \"outside\"\n    )\n    println( v )\n\n    e = Estimator( \"cler\" )\n\n    d = Data( e, s, v )\n\n    sol = grumps!( e, d )\n\n    println( sol )\n\n    Save( \"myresults.csv\", sol )\nend\n\nmyprogram()","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To see what is happening in the code, consider the function myprogram.  It first describes where data on consumers, products, market sizes, and random draws can be found.  This happens in the Sources call. In this example, all sources are files, but DataFrames are ok, also.  In addition, not all sources are needed for all estimators and options.  Indeed, only products data are required.  ","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"tip: Understanding data layout\nSee Spreadsheet formats for documentation of the spreadsheet formats.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"The utility specification for this example is, ","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"u_ijm = sum_k z_imk x_jmk theta_k^z + sum_k nu_imk x_jmk theta_k^nu + delta_jm + epsilon_ijm","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"where z are demographics, x are product level variables and nu are unobserved consumer heterogeneity (random coefficients).","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Variables describes what variables to include.  The precise variables included in demographics are specified in the first column of the matrix interactions and the product variables are included in the second. Random coefficients are on products specified by the randomcoefficients vector. Finally, the product characteristics included in delta are specified in the regressors vector. Instruments to include in the product level moments are specified in the instruments vector.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Variables are denoted by symbols corresponding to column headings of the provided spreadsheets or dataframes.  There are two different but equivalent versions of the Variables method: the only difference is the syntax to accommodate users' preferences.  The example here covers only one version. In this case, there are three interactions between demographic characteristics (in the first column) and product characteristics (in the second column).  ","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"In this particular example, :income and :age reference variables provided in the consumers and draws data, while :abv and :ibu appear in the products dataset. The outside good product uses the value \"outside\" in the :choice column of the consumers dataset.  :choice is a default name, which can be overridden using the option choice; share, product, and marketsize are likewise default names for share, product, and market size column headings in the product, product, and market size data sets respectively. Finally each observation in every dataset must be assigned to a market, so each must include a market identifier column whose default name is market (this can be overidden using the option market).","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"There are moreover random coefficients on the ibu and abv variables.  The product-level regressors and instruments that go into hat Pi are also entered.  Finally, the outsidegood argument indicates which value in the consumers spreadsheet is used to indicate that a product is the outside good.  There are many other choices; please see Variables() in the User Interface section.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"tip: Objects can be printed\nMost variables with data types created by Grumps can be printed.  For instance, the println( v ) line tells Grumps to print the variable v, which in this case contains information about the specification. println( d ) works too after the Data call.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"It then tells Grumps that it wants to use the full Grumps maximum likelihood estimator with penalized deviations from the macro moments in Estimator().  You could also have entered another descriptive string; Grumps is good at figuring out what you want.  Or you can use a symbol, like :cler.  In the Data call, it reads the data needed from the sources indicated in the Sources call using the information specified in the Variables call.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"The grumps! call then asks Grumps to compute the estimates.  The exclamation mark (bang) signifies that grumps! can change its arguments (this is standard Julia custom). grumps! uses this functionality to return internally specified options when called with the defaults. ","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Finally, Save saves the results to disk, in this case to a CSV file, but other formats are possible, also.  And the results can of course be printed, also, as the above program demonstrates.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Note that there are many other options and calls.  The main ones are described in the User Interface tab.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"tip: Getting help\nTo get help on a command, simply load Grumps in the REPL and type e.g.julia> ?Variables","category":"page"},{"location":"spreadsheet/#Spreadsheet-formats","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Recall that Grumps can take data from four different sources and in different formats.  Currently, only CSV files and DataFrames are implemented.  Recall that not all four sources are required for all estimators.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"tip: Files are preferable to dataframes\nThere is one advantage to providing file names instead of dataframes, and that is that Julia can release the memory allocated by the memory after return of the Data() call.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"As mentioned elsewhere, there is one spreadsheet (the products spreadsheet) that contains data on products, including e.g. price, market share, features, product level instruments (sxb in the paper).  If consumer choice data are used then such data can be entered via the consumers spreadsheet, which includes data on individual consumer choices, demographic characteristics, etcetera: anything that would typically have an i subscript in other words (yz in the paper).  A market size spreadsheet would contain information on the size of each market, i.e. the population in that market, which is only needed if the macro portion of the likelihood is to be used (N in the paper).  Finally, a demographic draws spreadsheet can be provided to be used in the macro likelihood portion of the objective function, i.e. z draws to use in the macro integration.  The format of each of these spreadsheets is described below.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"In the examples below, the data are comma separated, but that is not necessary: other formats can be specified in the Sources() call.  Column ordering is irrelevant.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"warning: Cases and spaces\nFor all spreadsheets be mindful of case and spaces.  That means omit spaces and be consistent in lower case versus upper case. For readability the spreadsheets below contain extra space i.e. they are aligned by comma; this is not advisable.  ","category":"page"},{"location":"spreadsheet/#Linking-between-spreadsheets","page":"Spreadsheet formats","title":"Linking between spreadsheets","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Grumps is flexible in naming conventions.  However, this requires that certain identifiers are common across spreadsheets. The following conventions should hold:","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"A market level identifier should be present in all spreadsheets using the same column heading. In the example below, this column heading is market. \nThe values of the market column in the marketsize spreadsheet should be unique. These values should link to the market columns in the product, consumer, and draws datasets.\nThe values of one column of the product dataset should be a unique identifier of a product within a market. In the example below, the heading for this column is product. \nThe values of one column in the consumer dataset should link to the unique identifier column of the product dataset. In the example below, the heading for this column is choice. \nAny variables used as demographics (z) should be present in both the consumer and draws datasets using identical column headings.  ","category":"page"},{"location":"spreadsheet/#Product-characteristics","page":"Spreadsheet formats","title":"Product characteristics","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"ibu ,  abv, share, IVgh_ibu, IVgh_abv, IVj_ibu, IVj_abv, market  , product\n1.09, 1.01, 0.01 , 12.57   , 11.45   , 4.78   , 5.09   , market 1, product 1\n2.85,-0.10, 0.13 , 10.52   ,  8.55   , 5.21   , 5.23   , market 1, product 2\n2.31, 0.55, 0.02 , 4.54    ,  7.26   , 5.91   , 5.52   , market 1, product 3","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The column headings are variable names.  Each row corresponds to a (market, product) pair and both these columns are required, albeit that the columns can have different names; market and product are just the defaults.  The markets have especially boring names in this example, but any string goes.  The same is true for products.  This spreadsheet does not need to include the outside good (indeed, leave it out) and shares would thus typically sum to a number less than one.  Which columns are to be used and where is  determined by the Variables call.  To use dummy variables, just insert a column with the corresponding characteristics (there can be multiple categories, which can be descriptive (e.g. strings)), which Grumps can turn into dummy variables automatically, as described in the Variables documentation.","category":"page"},{"location":"spreadsheet/#Consumer-characteristics","page":"Spreadsheet formats","title":"Consumer characteristics","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"income,  age, purchase, second,   market,     choice\n -1.20, 1.24,        8,     11, market 1,  product 8\n -0.64, 0.36,       11,      8, market 1, product 11\n -0.65, 1.32,        4,      3, market 1,  product 4\n -0.82, 0.77,       11,      4, market 1, product 11","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The columns are again variable names.  Each row corresponds to a consumer in the observed micro sample. Here, we need both market and choice, but the columns do not have to have those (default) headings.  The markets and products could have had more descriptive names (e.g. \"Pennsylvania\" instead of \"market 1\"), and the column headings could have been different as long as the above linking conventions are followed.","category":"page"},{"location":"spreadsheet/#Market-sizes","page":"Spreadsheet formats","title":"Market sizes","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"N     , market\n100000, market 1\n100000, market 2\n100000, market 3\n100000, market 4\n100000, market 5","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Each row corresponds to a market.  Again, the column headings can be adjusted and the ones presented here are the default ones.","category":"page"},{"location":"spreadsheet/#Draws","page":"Spreadsheet formats","title":"Draws","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"income,  age, market\n -1.60, 1.19, market 1\n -2.93, 1.23, market 1\n -1.78, 1.58, market 1\n -1.14, 1.70, market 1","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The rows of this spreadsheet correspond to consumers in the population, albeit their choice need not be observed.  The format and limitations for the draws spreadsheets is essentially the same as the other spreadsheets, but here each line corresponds to a (draw,market) pair. For markets for which market size information is available, one typically needs a number of demographic draws no less than the number of Monte Carlo draws to be used, where each draw is a vector of demographic characteristics that would be observed in the micro sample.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"warning: Draws and default macro integrator options\nUnless specified otherwise, the default macro integrator uses Monte Carlo integration with R = 10000 draws unless otherwise specified.  If one does not specify randomization then the default macro integrator simply uses the first R lines of draws for each market for demographics (z draws) and combines them with R draws from the distribution of the random coefficients (nu draws), both of which are then interacted with the product level regressors (x variables).  If the spreadsheet does not contain enough rows corresponding to a market then the program will cycle and throw a warning.  With randomization with replacement, R numbers are drawn from the draws spreadsheet regardless of the number of lines in the spreadsheet.  Without replacement, the same occurs and if the spreadsheet does not contain enough lines corresponding to the market, all lines are added and then the procedure is repeated.  In other words, there is replacement by necessity.  Again, a warning will be displayed. With randomization, the random numbers are drawn separately for each market.","category":"page"},{"location":"structure/#Directory-structure","page":"Directory structure","title":"Directory structure","text":"","category":"section"},{"location":"structure/#Top-level-folders","page":"Directory structure","title":"Top level folders","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"There are really two folders with sources:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"src for the programs\ndocs for the documentation","category":"page"},{"location":"structure/#src-folder","page":"Directory structure","title":"src folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Grumps is open source.  If you clone the repository at the github site you will have accesss to the full directory tree.","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Within src you will find the main package file Grumps.jl plus includes.jl, which loads all source code, and exports.jl which contains all exported symbols, i.e. symbols that you can use directly in your program without prefacing it with Grumps..","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Beyond that, you will find several folders in src:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"packages: loads all packages\ncommon: loads code that is common to several estimators\nestimators: code that is specific to one estimator\nintegrators: code that is specific to one integrator","category":"page"},{"location":"structure/#common-folder","page":"Directory structure","title":"common folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Within common there are a number of folders depending on the role they play in the program.  These are listed below.  ","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"array utilities for dealing with arrays\ndata data handling\nearly code that should be read and processed before other code\nerror error handling\nest code that gets called to compute estimators\nimports imports from other packages, mostly Base\ninference standard errors and such\nintegration numerical integration\nio reading data from and to files\noptim optimization\nprobs computation of choice probabilities\nsol handling solution object\nspace dealing with objects that reserve space ahead of time\nthreads multithreading objects\ntree contains code to print object types\ntypes contains code that defines object types\nutils contains miscellaneous utilities","category":"page"},{"location":"structure/#estimators-folder","page":"Directory structure","title":"estimators folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"The estimators folder contains a number of folders, one per estimator.  Each folder corresponds to a specific estimator.  For instance, cler contains code specific to the main Grumps estimator.","category":"page"},{"location":"structure/#integrators-folder","page":"Directory structure","title":"integrators folder","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"The integrators folder contains folders, one per integration method, for any integrators beyond the default integrators, which are handled under common.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"#Grumps.jl","page":"Home","title":"Grumps.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Grumps.jl is a package for computing random coefficients demand models using consumer and product level data. The main estimators are introduced in Grieco, Murry, Pinkse, and Sagl (2022), including:","category":"page"},{"location":"","page":"Home","title":"Home","text":"the conformant likelihood with exogeneity restrictions (CLER) estimator\nan asymptotically equivalent less expensive alternative thereof\nthe mixed data likelihood estimator (MDLE)\nthe share constrained likelihood estimator\nIn addition, other estimators have been implemented: \nmixed logit models (consumer level data only)\nmultinomial logit models (consumer level data only)\nGMM type random coefficient models in the style of Berry, Levinsohn, and Pakes (2004) (in process, not recommended)","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the notation of the paper, it solves problems of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"(hatdeltahatthetahatbeta) = textargmin_deltathetabeta big( - log hat L(deltatheta) + hatPi(deltabeta) big)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where log hat L is the sum of a micro loglikelihood and a macro loglikelihood and hatPi is a quadratic penalty term.  Any of the three components can be omitted if so desired. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Typically, log hat L is a sum over markets, products, and consumers whereas hatPi is a GMM-style squared norm of a vector-valued sum over markets.  Please see Grieco, Murry, Pinkse, and Sagl (2022) for details.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Several extensions are possible, which may require additions to the code. ","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation describes the use of the Grumps computer package.  It does not describe the estimators or algorithms.  Please refer to Grieco, Murry, Pinkse, and Sagl (2022) for that.  In addition, the code itself is documented, also.","category":"page"},{"location":"#Limitations","page":"Home","title":"Limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is still a preliminary version of Grumps, so please advise Joris Pinkse of any bugs, problems, shortcomings, missing features, etcetera.  Features it does not currently possess include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"sparse quadrature or similar integration methods\ndistributed computing\nGPUs\nstatistics other than coefficients, e.g. elasticities\nintegration methods for the micro portion of the GMM estimator other than quadrature\ntraditional GMM; see Grieco, Murry, Pinkse, and Sagl (2022) for details\nstandard errors for some of the estimators\ndetailed sanity checks","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of this code is subject to the MIT license.  This code includes a modified version of the Newton Method with Trust Regions code in the Optim package, which is also subject to the MIT license.","category":"page"},{"location":"example/#Example-program","page":"Example program","title":"Example program","text":"","category":"section"},{"location":"example/","page":"Example program","title":"Example program","text":"Below is a documented example program.  You can find a closely related example program in the extras/example folder.","category":"page"},{"location":"example/","page":"Example program","title":"Example program","text":"using Grumps\n\n\nfunction myprogram( nodes, draws, meth  )\n    # set which files contain the data to be used\n    s = Sources(                                                            \n      consumers = \"example_consumers.csv\",\n      products = \"example_products.csv\",\n      marketsizes = \"example_marketsizes.csv\",\n      draws = \"example_draws.csv\"  \n    )\n    \n    # set the specification to be used\n    v = Variables( \n        # these are the z_{im} * x_{jm} terms in the paper                                                         \n        interactions =  [                                                   \n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        # these are the x_{jm} * ν terms in the paper\n        randomcoefficients =  [:ibu; :abv],     \n        # these are the x_{jm} terms in the paper                            \n        regressors =  [ :constant; :ibu; :abv ],      \n        # these are the b_{jm} terms in the paper                      \n        instruments = [ :constant; :ibu; :abv; :IVgh_ibu; :IVgh_abv ], \n        # these are not needed for the estimators in the paper, just for GMM     \n        microinstruments = [                                                \n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n\n        # this is the label used for the outside good\n        outsidegood = \"product 11\"                                          \n    )\n    \n    # these are the data storage options; since these are the defaults, \n    # this can be omitted\n    # dop = DataOptions( ;micromode = :Hog, macromode = :Ant, balance = :micro )  \n\n    # these are the defaults so this line can be omitted, albeit that the default \n    # number of nodes may not be optimal\n    # ms = DefaultMicroIntegrator( nodes ) \n    # these are the defaults so this line can be omitted, albeit that the default \n    # number of draws may not be optimal                                   \n    # Ms = DefaultMacroIntegrator( draws )                                    \n\n    # creates an estimator object\n    e = Estimator( meth )                                                     \n\n    # this puts the data into a form Grumps can process\n    d = Data( e, s, v ) \n    # there are longhand forms if you wish to set additional parameters\n    # d = Data( e, s, v, ms, Ms; replicable = true )            \n\n    # no need to set this unless you wish to save memory (see memsave), \n    # will not exceed number of threads Julia is started with\n    # th = Grumps.GrumpsThreads( ; markets = 32 )                             \n\n    # redundant unless you wish to save memory\n    # o = Grumps.OptimizationOptions(; memsave = true, threads = th )         \n\n    # redundant unless you don't need standard errors on all coefficients\n    # seo = StandardErrorOptions(; δ = false )                                 \n\n    # compute estimates using automatic starting values\n    sol = grumps!( e, d )           \n    # long version to set more options                                          \n    # sol = grumps!( e, d, o, nothing, seo  )                                 \n    return sol\nend\n\n\nfor nodes ∈ [ 11 ] # , 17, 25]\n    for draws ∈ [ 10_000 ]  # , 100_000 ]\n        # other descriptive strings are allowed, as are the exact symbols\n        for meth ∈ [ \"cler\", \"mdle\", \"grumps share constraints\", \"mixed logit\", \"gmm\" ]         \n            @info \"$nodes $draws $meth\"\n            sol = myprogram( nodes, draws, meth ) \n            println( getθcoef( sol ), \"\\n\" )\n            println( sol, \"\\n\" )\n        end\n    end\nend","category":"page"}]
}
