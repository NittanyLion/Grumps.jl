var documenterSearchIndex = {"docs":
[{"location":"installation/#Installation-and-invocation","page":"Installation","title":"Installation and invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Parts of the explanation below applies once Grumps has been included into the Julia ecosystem","category":"page"},{"location":"installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Package installation is achieved in the usual way, i.e. by typing ]add Grumps in REPL.","category":"page"},{"location":"installation/#Invocation","page":"Installation","title":"Invocation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"Fire up Julia using julia -t 4 replacing the number 4 with whatever number of threads you wish to use.  The recommended number is the number of physical cores in your computer.  As a permanent solution, one can set the JULIA_NUM_THREADS environment variable.","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"Grumps can then be loaded with using Grumps.  That's it: you're ready to go.","category":"page"},{"location":"flow/#Algorithm-flow","page":"Algorithm flow","title":"Algorithm flow","text":"","category":"section"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"When Grumps is called using the grumps function, it runs est.jl in the optim folder.  This sets up various objects and then calls an optimizer with an objective function that is estimator-specific.  In other words, it will call a different method depending on the e argument in ObjectiveFunctionθ! in est.jl in the optim folder.","category":"page"},{"location":"flow/","page":"Algorithm flow","title":"Algorithm flow","text":"These methods ObjectiveFunctionθ! are defined either in one of the julia files in the optim folder whose name starts with obj, or in a specific estimator folder.  ObjectiveFunctionθ! then decides which internal optimizer (i.e. one that finds δ) to call: they're all called grumpsδ!.","category":"page"},{"location":"bearinmind/#Things-to-bear-in-mind","page":"Things to bear in mind","title":"Things to bear in mind","text":"","category":"section"},{"location":"bearinmind/#Starting-values","page":"Things to bear in mind","title":"Starting values","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The global objective function is convex in delta, so convergence of the inner optimization is generally uneventful.  Although the objective function is not convex in theta, the outer optimization often achieves the (near) optimum from a single starting value.  However, this is not guaranteed.  ","category":"page"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The most frequent case in which this would go wrong is when one or more of the theta^nu coefficients goes to zero and gets stuck.  This is more likely to happen when there are identification problems, e.g. when theta^z approx 0 and the product level moments do not provide much identifying power.  Just try a few other starting values.","category":"page"},{"location":"bearinmind/#Number-of-random-coefficients","page":"Things to bear in mind","title":"Number of random coefficients","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The program will become memory-hungry when the number of random coefficients is increased (assuming micro data are used).  There is a secondary problem that estimating many random coefficients will make estimating those random coefficients accurately more questionable.  Look at the memsave option to reduce memory consumption.","category":"page"},{"location":"bearinmind/#Zero-shares","page":"Things to bear in mind","title":"Zero shares","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) offers some robustness to shares that are equal to or very close to zero.  However, that requires that the product level moments are overidentified.","category":"page"},{"location":"bearinmind/#Efficiency","page":"Things to bear in mind","title":"Efficiency","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"The estimation procedure in Grieco, Murry, Pinkse, and Sagl (2022) requires an optimal weight matrix for the product level moments (GMM) portion if there is overidentification in the product level moments.  Currently, the algorithm assumes homoskedasticity and independence and produces correct estimates and standard errors under that assumption.  However, to obtain efficiency under those conditions one would have to estimate the error variance sigma_xi^2 and rerun the algorithm using the estimated sigma_xi^2 as a weight: see DataOptions on how to enter that choice.  Absent homoskedasticity and independence, one can transform the instruments to achieve the same goal.  This is something the use will have to do for herself in the current version of Grumps.  Note that the second stage can be started at the first stage estimates and should not take long to converge (relative to the first stage).","category":"page"},{"location":"bearinmind/#Floating-point-numbers","page":"Things to bear in mind","title":"Floating point numbers","text":"","category":"section"},{"location":"bearinmind/","page":"Things to bear in mind","title":"Things to bear in mind","text":"All numbers should be in the same floating point format.  The default (and only heavily tested) format is Float64, i.e. a 64-bit float.  But the code is designed to handle other formats.  This could be attractive if greater precision is desired.  So one could use some form of BigFloat, at the expense of increased memory use and a substantial increase in computation time.","category":"page"},{"location":"objects/#User-Interface","page":"User interface","title":"User Interface","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The sections below describe the main calls needed to use Grumps.  For any functions that are not documented here, simply use ? in the REPL, e.g. ?Variables.","category":"page"},{"location":"objects/#Data-entry","page":"User interface","title":"Data entry","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The methods below are used to enter data into Grumps.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Sources()\nVariables()","category":"page"},{"location":"objects/#Grumps.Sources-Tuple{}","page":"User interface","title":"Grumps.Sources","text":"Sources( \n    T           = DefaultSourceTypes; \n    consumers   :: Any = nothing, \n    products    :: Any = nothing, \n    marketsizes :: Any = nothing, \n    draws       :: Any = nothing,\n    user        :: Any = nothing\n)\n\nCreates a GrumpsSources object with source type entries of type T where the entries are provided in the optional parameters.\n\nGrumps (potentially) uses four data sources: a data source for consumer-level data, one for product-level data, one for market size information, and one for demographic draws.  Only the product-level data are required, but are by themselves insufficient.  For instance, for BLP95 one needs information on products, market sizes, and demographics; for the Grumps estimator one needs all four types of data; for a multinomial logit both consumer and product information are needed.  Not all data are needed for all markets.  For instance, it is ok for some estimators for there to be consumer-level data in some markets but not others.\n\nThe T argument is mostly there to allow for future expansion, so the description below applies to the case in which T = DefaultSourceTypes.\n\nBy default, the entries can be nothing, a string, a DataFrame, or a SourceFileType.  If an entry is nothing, it means that no such data is to be used.  If an entry is a string then it is converted to a SourceFileCSV entry with comma delimiter where the string name is the file name.  To use other source file types, create a SourceFileType first.  A DataFrame can be passed, also.  In all cases other than nothing, data will eventually be (converted to) a DataFrame and parsed from that.\n\nThe consumers variable specifies where consumer-level data can be found, the products variable is for the product-level data, marketsizes is for market sizes, and draws is for demographic draws; user has not been implemented yet.\n\nUse the Variables method to specify the way the data sources are formatted and the specification to estimate.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Variables-Tuple{}","page":"User interface","title":"Grumps.Variables","text":"function Variables( ; \n  market              :: Symbol = :market,\n  choice              :: Symbol = :choice,\n  interactions        :: Mat{Symbol} = [],\n  randomcoefficients  :: Vec{Symbol} = [],\n  outsidegood         :: String = \"outsidegood\",\n  share               :: Symbol = :share,\n  marketsize          :: Symbol = :N,\n  regressors          :: Vec{Symbol} = [],\n  instruments         :: Vec{Symbol} = [],\n  dummies             :: Vec{Symbol} = [],\n  nuisancedummy       :: Symbol = :none,\n  microinstruments    :: Mat{Symbol} = [],\n  user                :: Mat{Symbol} = []\n    )\n\nThis method creates an object of type GrumpsVariables.  It contains references to the variables that Grumps uses to create variables from the data sources specified by the call to the Sources function. \n\nFor instance, market is the column heading in the source spreadsheets for the market indicator.  This get's passed as a symbol, so the default (:market) says that the column heading is market, which is both case and spaces sensititve.  The same column heading  is used across all sources.  All entries with the exception of outsidegood refer to the column heading: outsidegood refers to the label used for the outside good, which should be the same across both spreadsheets and markets.\n\nmarket refers to the variable containing the market indicator in all input datasets\n\nproduct refers to the variable containing the product indicator in the product dataset\n\nchoice refers to the variable indicating the choice indicator in the consumer level datasets\n\ninteractions refers to the variables indicating consumer and product variable interactions (each row contains consumer variable, product variable)\n\nrandomcoefficients refers to the product level variables that have a random coefficient on them\n\noutsidegood refers to the label used for the outside good\n\nshare refers to the label used for the product level share\n\nmarketsize refers to the size of the market (number of people)\n\nregressors refers to the label used for the second stage regressors\n\ninstruments refers to the label used for the second stage instruments\n\ndummies refers to discrete variables to be converted to second stage dummy regressors and instruments\n\nnuisancedummy refers to at most one variable to be converted to a second stage dummy regressors and instrument whose coefficient value is of no interest\n\nmicroinstruments refers to micro instruments, which are only relevant for gmm style procedures\n\nuser refers to a list of variables to be added to the consumer-product interactions using a user-specified procedure\n\n\n\n\n\n","category":"method"},{"location":"objects/#Optimization-options","page":"User interface","title":"Optimization options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default optimization options are sensible, in which case this section can be skipped.  But for those who want to play with tolerances and such, have at it.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"There is one exception, however, and that exception pertains to using less memory.  There is a separate section dedicated to that possibility, namely Memory conservation","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"OptimizationOptions()\nOptimOptionsθ()\nOptimOptionsδ()\nGrumpsThreads(; blas = 0, markets = 0, inner = 0 )","category":"page"},{"location":"objects/#Grumps.OptimizationOptions-Tuple{}","page":"User interface","title":"Grumps.OptimizationOptions","text":"OptimizationOptions(; \nθopt = OptimOptionsθ(), \nδopt = OptimOptionsδ(), \nthreads = GrumpsThreads(), \nmemsave = false, \nmaxrepeats = 4, \nprobtype = :fast )\n\nSets the options used for numerical optimization.  θopt is used for the external optimization routine, δopt for the internal one.  These are both of type OptimOptions; see the OptimOptionsθ and OptimOptionsδ methods for elaboration.  The memsave variable is set to false by default; turning it on will reduce memory consumption significantly, but will also slow down computation.  The variable maxrepeats may disappear in the  future.  \n\nFinally, there are two ways of computing choice probabilities: robust and fast, specified by passing :robust or :fast in probtype. Fast choice probabilities are the default for good reason.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsθ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsθ","text":"OptimOptionsθ(; \nf_tol = 1.0e-8, \ng_tol = 1.0e-4, \nx_tol = 1.0e-5, \niterations = 25, \nshow_trace = true, \nstore_trace = true, \nextended_trace = true )\n\nCreates and returns an OptimOptions optimization options variable for the outer optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.OptimOptionsδ-Tuple{}","page":"User interface","title":"Grumps.OptimOptionsδ","text":"OptimOptionsδ( ; \nf_tol = 1.0e-8, \ng_tol = 1.0e-8, \nx_tol = 1.0e-6, \niterations = 25, \nshow_trace = false, \nstore_trace = true, \nextended_trace = false )\n\nCreates and returns an OptimOptions optimization options variable for the inner optimization algorithm, including the function value tolerance, the gradient tolerance, the solution tolerance, the maximum number of iterations, whether to show the trace, whether to store the trace, and whether to keep the extended trace.  See the Optim package for details.  \n\nThe current version of Grumps will largely ignore the trace-related parameters.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.GrumpsThreads-Tuple{}","page":"User interface","title":"Grumps.GrumpsThreads","text":"GrumpsThreads(; \n    blas = 0, \n    markets = 0, \n    inner = 0 \n    )\n\nThis sets the number of threads to be used subject to a number of caveats.  blas refers to the number of BLAS threads, markets to the number of threads in loops over markets, and inner to the number of threads in inner loops.  A value of zero forces the automatic selection of the number of threads.\n\nOf these, inner is not currently used at all, market is only used in memsave mode, and blas is used.  However, please note that the number of threads used by Grumps altogether is the number of threads passed in via the command line argument (i.e. via the -t switch), where that number does not include the number of BLAS threads set.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Data-storage-options","page":"User interface","title":"Data storage options","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The default data storage options are sensible, but some space can be saved by tinkering with the settings.  However, the only parameter that is worth changing is σ2, which is the variance of ξ, the product level error term.  This is of no relevance for two-stage estimators like unpenalized mle.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"DataOptions()","category":"page"},{"location":"objects/#Grumps.DataOptions-Tuple{}","page":"User interface","title":"Grumps.DataOptions","text":"DataOptions(; \n    micromode   = :Hog\n    macromode   = :Ant\n    balance     = :micro\n    σ2          = 1.0\n)\n\nSpecifies how Grumps should store its data and what it should store.  The first three options are best left alone, unless you know what it is you're doing.  The last option is the variance of ξ, i.e. the error variance in the product level moments.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Estimator-choice","page":"User interface","title":"Estimator choice","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps can compute quite a few estimators and one can specify which estimator to use by passing the return value of a call to Estimator to the optimization routine.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The easiest way to call Estimator is by passing it a string that describes what it is that you want to do.  The following estimators are currently defined:","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"the full Grumps estimator\nGrumps-style maximum likelihood, i.e Grumps without penalty\nditto, but imposing share constraints\nGMM estimator that uses both micro and macro moments and uses quadrature instead of Monte Carlo draws in the micro moments.  The micro moments are `smart' in that they condition on z_im instead of integrating it out.\na mixed logit estimator","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Estimator( s :: String )\nEstimator( s :: Symbol )\nEstimators()","category":"page"},{"location":"objects/#Grumps.Estimator-Tuple{String}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: String )\n\nCreates and returns a GrumpsEstimator type.  Grumps is reasonably good at figuring out what it is that you want, so e.g. Estimator( \"maximum likelihood\" ) gives you the unpenalized Grumps maximum likelihood estimator.\n\nThe estimators currently programmed include:\n\nthe full Grumps estimator\nGrumps-style maximum likelihood, i.e Grumps without penalty\nditto, but imposing share constraints\nGMM estimator that uses both micro and macro moments and uses quadrature instead of Monte Carlo draws in the micro moments.  The micro moments are `smart' in that they condition on z_im instead of integrating it out.\na mixed logit estimator\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimator-Tuple{Symbol}","page":"User interface","title":"Grumps.Estimator","text":"Estimator( s :: Symbol )\n\nCreates and returns a GrumpsEstimator type.\n\nThis is one method of specifying the estimator used.  However, it is unforgiving in that the exact symbol used internally must be passed, so the Estimator( s :: String ) method is usually a better choice.\n\nPossible choices include:\n\n:pml the full Grumps maximum likelihood estimator  \n\n:vanilla the unpenalized Grumps maximum likelihood estimator\n\n:shareconstraint the unpenalized Grumps maximum likelihood estimator with share constraints\n\n:gmm GMM estimator that uses both micro and macro moments\n\n:mixedlogit mixed logit maximum likelihood estimator\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.Estimators-Tuple{}","page":"User interface","title":"Grumps.Estimators","text":"Estimators( )\n\nPrints a list of available estimators.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Choice-of-integration-method-(integrators)","page":"User interface","title":"Choice of integration method (integrators)","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Grumps uses separate integration methods for the micro and macro components. The default choices are simple with small numbers of nodes and draws. For micro, it is Hermitian quadrature, for macro it's Monte Carlo draws. One gets the defaults if the choices are omitted.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"The procedure is to create the integrators using a call to BothIntegrators with the desired integrators as arguments and then pass this in your call to Data.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"BothIntegrators( :: MicroIntegrator{T}, ::MacroIntegrator{T} ) where {T<:AbstractFloat}\nDefaultMicroIntegrator( ::Int, ::Type )\nDefaultMacroIntegrator( ::Int, ::Type )","category":"page"},{"location":"objects/#Grumps.BothIntegrators-Union{Tuple{T}, Tuple{MicroIntegrator{T}, MacroIntegrator{T}}} where T<:AbstractFloat","page":"User interface","title":"Grumps.BothIntegrators","text":"BothIntegrators( microIntegrator :: MicroIntegrator{T}, macroIntegrator :: MacroIntegrator{T} )\n\nCreates the type BothIntegrators containing both the indicated microIntegrator and macroIntegrator.  \n\nEither argument can be omitted.  If both arguments are omitted then one can pass the floating point type T instead.  If no floating point type is passed then a Float64 is assumed.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMicroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMicroIntegrator","text":"DefaultMicroIntegrator( n :: Int, T :: Type )\n\nCreates a basic quadrature Integrator using n nodes in each dimension.  Type T can be omitted, in which case it is Float64.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.DefaultMacroIntegrator-Tuple{Int64, Type}","page":"User interface","title":"Grumps.DefaultMacroIntegrator","text":"DefaultMacroIntegrator( n :: Int, T :: Type )\n\nCreates a basic Monte Carlo Integrator using n draws.  Type T can be omitted, in which case it is Float64.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Data-object-creation","page":"User interface","title":"Data object creation","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"The data stored in spreadsheets or other objects have to be converted into a form that Grumps understands.  The call to Data achieves that.   It takes as inputs the various choices made by the user and then creates an appropriate data object that is subsequently passed to the optimization call.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"Data()","category":"page"},{"location":"objects/#Grumps.Data-Tuple{}","page":"User interface","title":"Grumps.Data","text":"Data( \n    e                   :: GrumpsEstimator,\n    ss                  :: Sources,\n    v                   :: Variables,\n    integrators            :: GrumpsIntegrators = BothIntegrators(),\n    T                   :: Type = F64,\n    u                   :: UserEnhancement = DefaultUserEnhancement();\n    options             :: DataOptions = GrumpsDataOptions()\n    )\n\nTakes user inputs and converts them into an object that Grumps can understand.  This is synonymous with GrumpsData(...).\n\nData takes the following arguments, of which the first three are mandatory:\n\ne:                   estimator; see Estimator\nss:                  cata sources; see Sources\nv:                   variables to be used; see Variables\nintegrators:            see BothIntegrators, DefaultMicroIntegrator, and DefaultMacroIntegrator\nT:                   floating point type; not heavily tested\nu:                   not yet implemented\noptions:             data options to be used, see DataOptions\n\n\n\n\n\n","category":"method"},{"location":"objects/#Algorithm-call","page":"User interface","title":"Algorithm call","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"Once all data structures have been put together, one can call the algorithm.  This is straightforward.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"    grumps!( ::Estimator, ::Data{T}, ::OptimizationOptions, ::Grumps.StartingVector{T}, ::StandardErrorOptions ) where {T<:Grumps.Flt}","category":"page"},{"location":"objects/#Grumps.grumps!-Union{Tuple{T}, Tuple{Estimator, Data{T}, OptimizationOptions, Union{Nothing, Vector{T}}, StandardErrorOptions}} where T<:AbstractFloat","page":"User interface","title":"Grumps.grumps!","text":"grumps( \n    e       :: Estimator,\n    d       :: Data{T},\n    o       :: OptimizationOptions = OptimizationOptions(),\n    θstart  :: StartingVector{T} = nothing,\n    seo     :: StandardErrorOptions = StandardErrorOptions()\n)\n\nConducts the optimization.  You typically just want to set θstart to nothing, i.e. have a starting vector  picked automatically.  \n\n\n\n\n\n","category":"method"},{"location":"objects/#Retrieving-results","page":"User interface","title":"Retrieving results","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"As noted above, Grumps will return its results in a GrumpsSolution variable that can be queried as follows.  to be expanded","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"getθ( sol :: GrumpsSolution )\ngetδ( sol :: GrumpsSolution )\ngetβ( sol :: GrumpsSolution )\ngetcoef( e :: GrumpsEstimate )\ngetstde( e :: GrumpsEstimate )\ngettstat( e :: GrumpsEstimate )\ngetname( e :: GrumpsEstimate )","category":"page"},{"location":"objects/#Grumps.getθ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getθ","text":"getθ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for θ that can be queried for results.  See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getδ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getδ","text":"getδ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for δ that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getβ-Tuple{GrumpsSolution}","page":"User interface","title":"Grumps.getβ","text":"getβ( sol :: GrumpsSolution )\n\nReturns a vector of GrumpsEstimate types for β that can be queried for results. See  getcoef, getstde, gettstat, and getname.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getcoef-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getcoef","text":"getcoef( e :: GrumpsEstimate )\n\nReturns the estimated coefficient value.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getstde-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getstde","text":"getstde( e :: GrumpsEstimate )\n\nReturns the standard error.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.gettstat-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.gettstat","text":"gettstat( e :: GrumpsEstimate )\n\nReturns the t statistic.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Grumps.getname-Tuple{GrumpsEstimate}","page":"User interface","title":"Grumps.getname","text":"getname( e :: GrumpsEstimate )\n\nReturns the variable name.\n\n\n\n\n\n","category":"method"},{"location":"objects/#Memory-conservation","page":"User interface","title":"Memory conservation","text":"","category":"section"},{"location":"objects/","page":"User interface","title":"User interface","text":"stub; this section to be completed","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"By default, Grumps loads all data and then creates space for all markets for things like choice probabilities, objective functions and their derivatives, intermediate objects, etcetera.  This saves computation time, but eats memory, especially as the number of random coefficients increases.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"To conserve memory, one can set memsave in OptimizationOptions() to true.  What this does is that it shares space for choice probabilities and related objects across a number of markets.  For instance, if there are ten markets and the number of market threads in OptimizationOptions() is set to two then the space for choice probabilities is shared across five markets.  These choices will have no effect if the number of market threads is no less than the number of markets.  The downside of doing this is that it slows down computation since choice probabilities need to be recomputed.  This is especially true for estimators that use the penalty term.","category":"page"},{"location":"objects/","page":"User interface","title":"User interface","text":"There are less impactful ways of reducing memory usage, such as choosing the option :Ant for the micro data, also.  *** not yet implemented ***","category":"page"},{"location":"extending/#Extending-Grumps","page":"Extending Grumps","title":"Extending Grumps","text":"","category":"section"},{"location":"extending/","page":"Extending Grumps","title":"Extending Grumps","text":"to be done","category":"page"},{"location":"quickstart/#Quick-Start-Guide","page":"Quick start","title":"Quick Start Guide","text":"","category":"section"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To use Grumps.jl consider the following program, which computes the unpenalized maximum likelihood estimator of Grieco, Murry, Pinkse, and Sagl.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"using Grumps, LinearAlgebra\n\n\nBLAS.set_num_threads(8)\n\nfunction myprogram(  )\n\n    @info \"setting source files\"\n    s = Sources(\n    consumers = \"_example_consumers.csv\",\n    products = \"_example_products.csv\",\n    marketsizes = \"_example_marketsizes.csv\",\n    draws = \"_example_draws.csv\"  \n    )\n    println( s )\n\n     v = Variables(\n        interactions =  [\n            :income :constant; \n            :income :ibu; \n            :age :ibu\n            ],\n        randomcoefficients =  [:ibu; :abv],\n        regressors =  [ :constant; :ibu; :abv ],\n        instruments = [ :constant; :ibu; :abv; :IVgh_ibu; :IVgh_abv ],\n        outsidegood = \"outside\"\n    )\n    println( v )\n\n    e = Estimator( \"pml\" )\n\n    d = Data( e, s, v )\n\n     sol = grumps!( e, d )\n\n     println( sol )\nend\n\nmyprogram()","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To see what is happening in the code, consider the function myprogram.  It first describes where data on consumers, products, market sizes, and random draws can be found.  This happens in the Sources call. In this example, all sources are files, but DataFrames are ok, also.  In addition, not all sources are needed for all estimators and options.  Indeed, only products data are required.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Next, in Variables it describes what variables to include.  In this case, there are three interactions between demographic characteristics (in the first column) and product characteristics (in the second column).  There are moreover random coefficients on the ibu and abv variables.  The product-level regressors and instruments that go into hat Pi are also entered.  Finally, the outsidegood argument indicates which value in the consumers spreadsheet is used to indicate that a product is the outside good.  There are many other choices; please see the User Interface section.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"It then tells Grumps that it wants to use the full Grumps maximum likelihood estimator with penalized deviations from the macro moments in Estimator.  You could also have entered another descriptive string; Grumps is pretty good at figuring out what you want.  Or you can use a symbol, like :mle.  In the Data call, it reads the data needed from the sources indicated in the Sources call using the information specified in the Variables call.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"The grumps! call then asks Grumps to compute the estimates.  The exclammation mark (bang') signifies thatgrumps!` can change its arguments, including the starting value.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"Note that there are many other options and calls.  The main ones are described in the User Interface tab.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"To get help on a command, simply load Grumps in the REPL and type e.g.","category":"page"},{"location":"quickstart/","page":"Quick start","title":"Quick start","text":"julia> ?Variables","category":"page"},{"location":"spreadsheet/#Spreadsheet-formats","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Recall that Grumps can take data from four different sources and in different formats.  Currently, only CSV files and DataFrames are implemented.  Recall that not all four sources are required for all estimators.","category":"page"},{"location":"spreadsheet/#Product-characteristics","page":"Spreadsheet formats","title":"Product characteristics","text":"","category":"section"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"Below are the first few lines of a CSV file.  ","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"ibu ,  abv, share, IVgh_ibu, IVgh_abv, IVj_ibu, IVj_abv, market  , product\n1.09, 1.01, 0.01 , 12.57   , 11.45   , 4.78   , 5.09   , market 1, product 1\n2.85,-0.10, 0.13 , 10.52   ,  8.55   , 5.21   , 5.23   , market 1, product 2\n2.31, 0.55, 0.02 , 4.54    ,  7.26   , 5.91   , 5.52   , market 1, product 3","category":"page"},{"location":"spreadsheet/","page":"Spreadsheet formats","title":"Spreadsheet formats","text":"The column headings are variable names.  Each line corresponds to a (market, product) pair.  The markets have especially boring names in this example, but any string goes.  The same is true for products.  This spreadsheet does not need to include the outside good (indeed, leave it out) and shares would typically sum to a number less than one.  Which columns are to be used and where is  determined by the Variables call.","category":"page"},{"location":"structure/#Directory-structure","page":"Directory structure","title":"Directory structure","text":"","category":"section"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"There are really two folders with sources:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"src for the programs\ndocs for the documentation","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Within src you will find the main package file Grumps.jl and includes.jl, which loads all source code.","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"Beyond that, you will find several folders:","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"packages: loads all packages\ncommon: loads code that is common to several estimators\ncode that is specific to one estimator, one folder per estimator","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"If you want to see how a particular data type is defined, just check out the types folder.  Since there are many types and subtypes, it can be handy to type GrumpsTypes() to get a list of some of the major ones.","category":"page"},{"location":"structure/","page":"Directory structure","title":"Directory structure","text":"If you wish to learn more about the algorithm itself, head to the optim folder.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"#Grumps.jl","page":"Home","title":"Grumps.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Grumps.jl is a package for computing random coefficients demand models, including:","category":"page"},{"location":"","page":"Home","title":"Home","text":"the penalized likelihood estimator of Grieco, Murry, Pinkse, and Sagl (2022)\nthe unpenalized likelihood estimator of Grieco, Murry, Pinkse, and Sagl (2022)\nGMM type random coefficient models in the style of Berry, Levinsohn, and Pakes (2004)\nGMM type random coefficient models in the style of Berry, Levinsohn, and Pakes (1995)\nMixed logit models\nMultinomial logit models","category":"page"},{"location":"","page":"Home","title":"Home","text":"It can handle problems of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"(hatdeltahatthetahatbeta) = textargmin_deltathetabeta big( - log hat L(deltatheta) + hatPi(deltabeta) big)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where log hat L is the sum of a micro loglikelihood and a macro loglikelihood and hatPi is a quadratic penalty term.  Any of the three components can be omitted if so desired. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Typically, log hat L is a sum over markets, products, and consumers whereas hatPi is a GMM-style squared norm of a vector-valued sum over markets.  Please see Grieco, Murry, Pinkse, and Sagl (2022) for details.","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation describes the use of the Grumps computer package.  It does not describe the estimators or algorithms.  Please refer to Grieco, Murry, Pinkse, and Sagl (2022) for that.  In addition, the code itself is documented, also.","category":"page"},{"location":"#Limitations","page":"Home","title":"Limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is still a preliminary version of Grumps, so please advise Joris Pinkse of any bugs, problems, shortcomings, missing features, etcetera.  Features it does not currently possess include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"sparse quadrature or similar integration methods\ndistributed computing\nGPUs\nstatistics other than coefficients, e.g. elasticities\nintegration methods for the micro portion of the GMM estimator other than quadrature\ntraditional GMM; see Grieco, Murry, Pinkse, and Sagl (2022) for details\nstandard errors for some of the estimators\ndetailed sanity checks","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of this code is subject to the MIT license.  This code includes a modified version of the Newton Method with Trust Regions code in the Optim package, which is also subject to the MIT license.","category":"page"},{"location":"example/#Example-program","page":"Example program","title":"Example program","text":"","category":"section"}]
}
